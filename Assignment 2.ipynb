{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load text from Project Gutenberg URL\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "url_template = 'http://www.gutenberg.org/cache/epub/1661/pg1661.txt'\n",
    "f = urllib.request.urlopen(url_template)\n",
    "text = f.read().decode(\"utf-8\") \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pre- Processing Part\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# Preprocessing part\n",
    "text=text.replace('\\n', ' ')\n",
    "text=text.replace('\"s', ' ')\n",
    "text=text.replace(',', ' ')\n",
    "text=text.replace('/s', ' ')\n",
    "text=text.replace('\"', ' ')\n",
    "text=text.replace (\"'\", '')\n",
    "text = text.lower()\n",
    "# text= re.sub('[(){}<>] ', ' ', text)\n",
    "\n",
    "sent_tokenize_list = sent_tokenize(text)\n",
    "# print(len(sent_tokenize_list))\n",
    "sent_start_end = []\n",
    "words = []\n",
    "\n",
    "# print(sent_tokenize_list)\n",
    "\n",
    "for sent in sent_tokenize_list:\n",
    "    sent = ' '.join(('<s>',sent,'</s>'))\n",
    "    sent = sent.replace('!', ' ')\n",
    "    sent = sent.replace('.', ' ')\n",
    "    sent = sent.replace('?', ' ')\n",
    "    sent = sent.replace('-', ' ')\n",
    "    sent = sent.replace('ï»¿', ' ')\n",
    "    sent = sent.replace('*', ' ')   \n",
    "    sent = sent.replace('\\n', ' ') \n",
    "    sent = sent.replace(':', ' ') \n",
    "    sent = sent.replace(';', ' ')    \n",
    "    \n",
    "#     sent = str(TextBlob(sent).correct())          \n",
    "    sent = re.sub( '\\s{2,}', ' ', sent).strip()    #Trying to remove extra spaces from sent\n",
    "#     print(sent)\n",
    "    for word in sent.split(' '):\n",
    "        words.append(word)     #Words List\n",
    "    sent_start_end.append(sent)  \n",
    "# print(sent_start_end[500:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens =  122392\n"
     ]
    }
   ],
   "source": [
    "# print(words [500:1000])\n",
    "print(\"Total Tokens = \", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting the file into 80% and 20%\n",
    "train, test = train_test_split(sent_start_end, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training token count 98318\n"
     ]
    }
   ],
   "source": [
    "word_train = []\n",
    "for sent in train:\n",
    "    for word in sent.split(' '):\n",
    "        word_train.append(word)                  #Training set words list\n",
    "print(\"Training token count\" , len(word_train))\n",
    "# print(word_train[69000:70000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing token count 24074\n"
     ]
    }
   ],
   "source": [
    "word_test = []\n",
    "for sent in test:\n",
    "    for word in sent.split(' '):\n",
    "        word_test.append(word)                  #Testing set words list\n",
    "print(\" Testing token count\", len(word_test))\n",
    "# print(word_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training token Count (seen) = 98318\n",
      "Distinct Unigrams count = 7486\n",
      "Expected Unigrams Count =  7486\n",
      "Top 10 MLE for unigram\n",
      "[('<s>', 0.055961), ('</s>', 0.055961), ('the', 0.047611), ('and', 0.024929), ('i', 0.0244), ('to', 0.02319), ('of', 0.022793), ('a', 0.022153), ('in', 0.015104), ('that', 0.014494)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "unigram_count=Counter(word_train)\n",
    "\n",
    "#MLE Probabilities of unigram\n",
    "sum2 = 0\n",
    "for key in unigram_count:\n",
    "    sum2 = float(sum2 + unigram_count.get(key))\n",
    "\n",
    "unigram_prob = {}\n",
    "for key in unigram_count:\n",
    "    unigram_prob[key] = round( unigram_count.get(key) / sum2, 6)\n",
    "\n",
    "#Displaying the results for unigrams\n",
    "print(\"Total training token Count (seen) =\" , len(word_train))\n",
    "# print(\"Distict Tokens = \", len(set(word_train)))\n",
    "print(\"Distinct Unigrams count =\", len(unigram_count))\n",
    "print(\"Expected Unigrams Count = \", len(unigram_count)   )\n",
    "gram1 = sorted(unigram_prob.items(), key=lambda count: count[1], reverse =True)\n",
    "print(\"Top 10 MLE for unigram\")\n",
    "print (gram1[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training bigram count (seen) = 98317\n",
      "Corpus Training bigram count (distinct) = 43045\n",
      "Expected Training bigram Count (distinct) =  56040196\n",
      "Top 10 MLE for bigram\n",
      "[('<s> eight', 0.000182), ('<s> nay', 0.000182), ('<s> imitated', 0.000182), ('<s> heh', 0.000182), ('<s> step', 0.000182), ('<s> oscillation', 0.000182), ('<s> fine', 0.000182), ('<s> quick', 0.000182), ('<s> voilà', 0.000182), ('<s> must', 0.000182)]\n"
     ]
    }
   ],
   "source": [
    "####Bigram tokens\n",
    "\n",
    "biwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-1:\n",
    "        break\n",
    "    biwords.append(item+' '+word_train[index+1])\n",
    "# print(biwords)\n",
    "bigram_count = Counter(biwords)\n",
    "\n",
    "# Bigram Probabilities with and without smoothing\n",
    "bigram_prob = {}\n",
    "for key in bigram_count:\n",
    "    uniword = key.split(' ')\n",
    "#     print(uniword[0])\n",
    "#     print(key)\n",
    "    if (bigram_count[key] == 0):\n",
    "        bigram_prob[key] =0\n",
    "        bigram_prob_smooth[key] = 0\n",
    "    else:\n",
    "        bigram_prob[key] = round( bigram_count.get(key) / float(unigram_count.get(uniword[0])), 6)\n",
    "print(\"Corpus Training bigram count (seen) =\", sum(list(bigram_count.values())))\n",
    "print(\"Corpus Training bigram count (distinct) =\", len(bigram_count))\n",
    "print(\"Expected Training bigram Count (distinct) = \", (len(unigram_count) * len(unigram_count)))  \n",
    "\n",
    "#displaying Probabilities for bigram\n",
    "gram2 = sorted(bigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Top 10 MLE for bigram\")\n",
    "print (gram2[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training trigram count (seen) = 98316\n",
      "Corpus Training trigram count (distinct) = 74245\n",
      "Training Expected trigrams Count (distinct) =  419516907256\n",
      "Least 10 MLE for trigram\n",
      "[('</s> <s> eight', 0.000182), ('</s> <s> nay', 0.000182), ('</s> <s> imitated', 0.000182), ('</s> <s> heh', 0.000182), ('</s> <s> step', 0.000182), ('</s> <s> oscillation', 0.000182), ('</s> <s> fine', 0.000182), ('</s> <s> quick', 0.000182), ('</s> <s> voilà', 0.000182), ('</s> <s> must', 0.000182)]\n"
     ]
    }
   ],
   "source": [
    "####Trigram Tokens\n",
    "triwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-2:\n",
    "        break\n",
    "    triwords.append(item+' '+word_train[index+1]+' '+word_train[index+2])\n",
    "trigram_count = Counter(triwords)\n",
    "\n",
    "trigram_prob = {}\n",
    "for key in trigram_count:\n",
    "    biword = key.split(' ')\n",
    "    trigram_prob[key] = round( trigram_count.get(key) / bigram_count.get(biword[0] +' ' + biword[1]), 6)\n",
    "\n",
    "\n",
    "print(\"Corpus Training trigram count (seen) =\", sum(list(trigram_count.values())))\n",
    "print(\"Corpus Training trigram count (distinct) =\", len(trigram_count))\n",
    "print(\"Training Expected trigrams Count (distinct) = \", len(unigram_count) * len(unigram_count) * len(unigram_count)   )\n",
    "\n",
    "gram3 = sorted(trigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Least 10 MLE for trigram\")\n",
    "print (gram3[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training quadrigram count (seen) = 98315\n",
      "Corpus Training quadrigram count (distinct) = 89376\n",
      "Expected quadrigrams Count (distinct) =  3140503567718416\n",
      "Least 10 MLE for quadrigram\n",
      "[('</s> <s> i smiled', 0.001253), ('</s> <s> i roared', 0.001253), ('</s> <s> i staggered', 0.001253), ('</s> <s> i bowed', 0.001253), ('</s> <s> i shook', 0.001253), ('</s> <s> i slept', 0.001253), ('</s> <s> i wired', 0.001253), ('</s> <s> i placed', 0.001253), ('</s> <s> i deduced', 0.001253), ('</s> <s> i got', 0.001253)]\n"
     ]
    }
   ],
   "source": [
    "####Quadrigram Tokens\n",
    "\n",
    "quadriwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-3:\n",
    "        break\n",
    "    quadriwords.append(item+' '+word_train[index+1]+' '+word_train[index+2]+' '+word_train[index+3])\n",
    "quadrigram_count = Counter(quadriwords)\n",
    "# print(quadrigram_count)\n",
    "\n",
    "quadrigram_prob = {}\n",
    "for key in quadrigram_count:\n",
    "    triword = key.split(' ')\n",
    "#     print(triword[0:3])\n",
    "#     print(key)\n",
    "    quadrigram_prob[key] = round( quadrigram_count.get(key) / trigram_count.get(triword[0] +' ' + triword[1]+' ' + triword[2]), 6)\n",
    "# print(quadrigram_prob)\n",
    "\n",
    "print(\"Corpus Training quadrigram count (seen) =\", sum(list(quadrigram_count.values())))\n",
    "print(\"Corpus Training quadrigram count (distinct) =\", len(quadrigram_count))\n",
    "print(\"Expected quadrigrams Count (distinct) = \", len(unigram_count) * len(unigram_count) * len(unigram_count)  * len(unigram_count)  )\n",
    "\n",
    "gram4 = sorted(quadrigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Least 10 MLE for quadrigram\")\n",
    "print (gram4[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training pentigram count (seen) = 98314\n",
      "Corpus Training pentigram count (distinct) = 95478\n",
      "Expected pentigrams Count =  23509809707940062176\n",
      "Least 10 MLE for pentigram\n",
      "[('</s> <s> it is just', 0.007634), ('</s> <s> it is nothing', 0.007634), ('</s> <s> it is cabinet', 0.007634), ('</s> <s> it is easy', 0.007634), ('</s> <s> it is our', 0.007634), ('</s> <s> it is high', 0.007634), ('</s> <s> it is likely', 0.007634), ('</s> <s> it is unthinkable', 0.007634), ('</s> <s> it is certain', 0.007634), ('</s> <s> it is i', 0.007634)]\n"
     ]
    }
   ],
   "source": [
    "####Pentigram Tokens\n",
    "\n",
    "pentiwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-4:\n",
    "        break\n",
    "    pentiwords.append(item+' '+word_train[index+1]+' '+word_train[index+2]+' '+word_train[index+3]+' '+word_train[index+4])\n",
    "pentigram_count = Counter(pentiwords)\n",
    "# print(pentigram_count)\n",
    "\n",
    "pentigram_prob = {}\n",
    "for key in pentigram_count:\n",
    "    quadriword = key.split(' ')\n",
    "#     print(quadriword[0:4])\n",
    "#     print(key)\n",
    "    pentigram_prob[key] = round( pentigram_count.get(key) / quadrigram_count.get(quadriword[0] +' ' + quadriword[1]+' ' + quadriword[2]+' ' + quadriword[3]), 6)\n",
    "# print(pentigram_prob)\n",
    "\n",
    "print(\"Corpus Training pentigram count (seen) =\", sum(list(pentigram_count.values())))\n",
    "print(\"Corpus Training pentigram count (distinct) =\", len(pentigram_count))\n",
    "print(\"Expected pentigrams Count = \", len(unigram_count) * len(unigram_count) * len(unigram_count)  * len(unigram_count) * len(unigram_count)  )\n",
    "\n",
    "gram5 = sorted(pentigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Least 10 MLE for pentigram\")\n",
    "print (gram5[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Building nested dictionary \n",
    "import random\n",
    "unigram_dictt = {}\n",
    "bigram_dictt = {}\n",
    "trigram_dictt = {}\n",
    "quadrigram_dictt = {}\n",
    "pentigram_dictt = {}\n",
    "def build_dictionary(model):\n",
    "    if model == \"unigram\":\n",
    "#         print(\"Unigram Dictionary\")\n",
    "        for i in range(len(words)): \n",
    "            if not unigram_dictt.get(words[i]): \n",
    "                unigram_dictt[words[i]] = 1 \n",
    "            else: \n",
    "                unigram_dictt[words[i]] += 1 \n",
    "        summ = sum (unigram_dictt.values())\n",
    "\n",
    "        for key in unigram_dictt:\n",
    "            prob =round(unigram_dictt.get(key) / summ,6)\n",
    "            unigram_dictt[key] = prob\n",
    "\n",
    "\n",
    "        gram1_iter= iter(unigram_dictt)\n",
    "\n",
    "        \n",
    "    if model == \"bigram\":\n",
    "#         print(\"bigram dictionary\")\n",
    "        for i in range(len(words) - 1): \n",
    "            if not bigram_dictt.get(words[i]): \n",
    "                bigram_dictt[words[i]] = {} \n",
    "            if not bigram_dictt[words[i]].get(words[i+1]): \n",
    "                bigram_dictt[words[i]][words[i+1]] = 1 \n",
    "            else: \n",
    "                bigram_dictt[words[i]][words[i+1]] += 1 \n",
    "        for outer_key in bigram_dictt:\n",
    "            subdict = dict(bigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                bigram_dictt[outer_key][inner_key] = prob\n",
    "        gram2_iter= iter(bigram_dictt)\n",
    "\n",
    "\n",
    "    elif model == \"trigram\":  \n",
    "#         print(\"trigram ditionary\")\n",
    "        for i in range(len(words) - 2): \n",
    "            if not trigram_dictt.get(words[i] + ' ' + words[i+1]): \n",
    "                trigram_dictt[words[i] + ' ' + words[i+1]] = {} \n",
    "            if not trigram_dictt[words[i] + ' ' + words[i+1]].get(words[i+2]): \n",
    "                trigram_dictt[words[i] + ' ' + words[i+1]][words[i+2]] = 1 \n",
    "            else: \n",
    "                trigram_dictt[words[i] + ' ' + words[i+1]][words[i+2]] += 1 \n",
    "    \n",
    "        for outer_key in trigram_dictt:\n",
    "            subdict = dict(trigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                trigram_dictt[outer_key][inner_key] = prob\n",
    "                \n",
    "    \n",
    "        gram3_iter= iter(trigram_dictt)\n",
    "\n",
    "        \n",
    "    elif model == \"quadrigram\":\n",
    "#         print(\"quadrigram dictionary\")\n",
    "        for i in range(len(words) - 3): \n",
    "            if not quadrigram_dictt.get(words[i] + ' ' + words[i+1] + ' ' + words [i+2]): \n",
    "                quadrigram_dictt[words[i] + ' ' + words[i+1]+ ' ' + words[i+2]] = {} \n",
    "            if not quadrigram_dictt[words[i] + ' ' + words[i+1] +' ' + words[i+2]].get(words[i+3]): \n",
    "                quadrigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]][words[i+3]] = 1 \n",
    "            else: \n",
    "                quadrigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]][words[i+3]] += 1 \n",
    "        for outer_key in quadrigram_dictt:\n",
    "            subdict = dict(quadrigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                quadrigram_dictt[outer_key][inner_key] = prob\n",
    "        gram4_iter= iter(quadrigram_dictt)\n",
    "\n",
    "\n",
    "    elif model == \"pentigram\":\n",
    "#         print(\"pentigram dictionary\")\n",
    "        for i in range(len(words) - 4): \n",
    "            if not pentigram_dictt.get(words[i] + ' ' + words[i+1] + ' ' + words [i+2]+ ' ' + words [i+3]): \n",
    "                pentigram_dictt[words[i] + ' ' + words[i+1]+ ' ' + words[i+2]+ ' ' + words [i+3]] = {} \n",
    "            if not pentigram_dictt[words[i] + ' ' + words[i+1] +' ' + words[i+2]+ ' ' + words [i+3]].get(words[i+4]): \n",
    "                pentigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]+ ' ' + words [i+3]][words[i+4]] = 1 \n",
    "            else: \n",
    "                pentigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]+ ' ' + words [i+3]][words[i+4]] += 1 \n",
    "        for outer_key in pentigram_dictt:\n",
    "            subdict = dict(pentigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                pentigram_dictt[outer_key][inner_key] = prob\n",
    "        gram5_iter= iter(pentigram_dictt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Generating Random sentences based on unigram ***********************\n",
      "\n",
      "<s> tones pitch fireplace frock further folk downstairs amount especially unique distinction shorter affected contraction nerves commander leg entitles oldest vagabonds addicted goose fitness settles cart buried cooking earliest unmarried</s> \n",
      "\n",
      "<s> logician accident performing distracting wander outsides folly format hydraulic commerce intently approaching forestalling safely edge miles crawl offices cheerful sized attainments transition boots identification thrust outskirts proportion thats pack</s> \n",
      "\n",
      "<s> clearer flattening neck jacksons negro tangible rucastles relate tailless snigger amuse crate run loftily payment shelves wits introduce rucastles threatening pedestrians mining introspective clerk inception allude treat souvenir breathing</s> \n",
      "\n",
      "<s> waiter loans scale reveal completed resources this hes unburned include eclipses paying reconsider wreck benefactor solicitation frightened freemason overcoat slice swain mustard cubic actress demon excellent ex shadow scala</s> \n",
      "\n",
      "<s> must accidental station fresno discovering turns additions thems control actions bandaged fortunate solemnly breathlessly given random shimmering unfeigned warned injured injuring postmark aged furniture indisposition aid 77 counsel subsided</s> \n",
      "\n",
      "<s> competition posted morcar west charged someone enlarged crewe league clue refusal slice menaced concept eyes red quarrelling fitting tiara wing conviction gratitude terminated restore losing tire cab looking ebook</s> \n",
      "\n",
      "<s> greasy stocked ransacked air factories safes steep platform trunks elder cosy mass fatigued dusk brains took womans waddling beating haired witnesses purses melbourne rolled nostrils story harshly u trustees</s> \n",
      "\n",
      "<s> wit visited cubic prize carefully features alas backwaters wrinkles producing clink gilt like reptiles utilise trough brides reveal available systematic proceedings issue francisco pencil odessa plush bedded tremor napoleons</s> \n",
      "\n",
      "*********************Generating Random sentences based on bigram ***********************\n",
      "\n",
      "<s> give provided always locked your guilt more respectable figure like an enclosure here last which shows you took that they made all assembled round are men before taking a</s> \n",
      "\n",
      "<s> starving </s></s> \n",
      "\n",
      "<s> had remarked a dense tobacco with diligence that murmured holmes when our visit http //gutenberg net/license) </s></s> \n",
      "\n",
      "<s> who drove back so simple faith in so remarkable </s></s> \n",
      "\n",
      "<s> name to puzzle it hard work (b) alteration modification or so secluded after an ideal spring and frogged jacket and sleeves the curious as public possessions of major freebody</s> \n",
      "\n",
      "<s> not possible bearing </s></s> \n",
      "\n",
      "<s> farewell then for within me too far too crowded even threatening her initials is obvious from what dyou want the trail in lieu of articles with reference beside him</s> \n",
      "\n",
      "<s> singularity is anything since gives his favour </s></s> \n",
      "\n",
      "*********************Generating Random sentences based on trigram ***********************\n",
      "\n",
      "<s> disregarding my  presence  here  and  ill  gentlemen  ostlers  and  servant  maids  joined  in  a  knot </s> \n",
      "\n",
      "<s> local aid  is  always  instructive  </s> </s> \n",
      "\n",
      "<s> hitherto his  orgies  had  always  laughed  at  for  my  skill  </s> </s> \n",
      "\n",
      "<s> eh </s> </s> \n",
      "\n",
      "<s> six out  and  seized  the  intruder  by  the  internal  revenue  service  </s> </s> \n",
      "\n",
      "<s> those i  think  perhaps  it  is  extremely  improbable  that  he  thought  of  death  </s> </s> \n",
      "\n",
      "<s> precisely so  on  december  22nd  </s> </s> \n",
      "\n",
      "<s> contact the  foundation  the  trademark  owner  any  agent  or  employee  of  the  dying  woman  </s> </s> \n",
      "\n",
      "*********************Generating Random sentences based on quadrigram ***********************\n",
      "\n",
      "<s> beyond the obvious  facts  that  he  has  not  been  brushed  for  weeks  </s> </s> \n",
      "\n",
      "<s> mark that point  </s> </s> \n",
      "\n",
      "<s> shillings have not  been  able  to  gather  about  the  families  </s> </s> \n",
      "\n",
      "<s> bring me the  books  bill  said  he  </s> </s> \n",
      "\n",
      "<s> coarse writing murmured  holmes  </s> </s> \n",
      "\n",
      "<s> pon my word  watson  you  are  coming  along  wonderfully  </s> </s> \n",
      "\n",
      "<s> royalty payments must  be  paid  within  60  days  following  each  date  on  which  you  prepare  (or </s> \n",
      "\n",
      "<s> among my headings  under  this  one  twelve  months  i  find  an  account  of  the  next  act </s> \n",
      "\n",
      "*********************Generating Random sentences based on pentigram ***********************\n",
      "\n",
      "<s> suddenly to my horror  there  was  a  distinct  sound  of  footsteps  moving  softly  in  the  next </s> \n",
      "\n",
      "<s> of my mother </s> </s> \n",
      "\n",
      "<s> anything else </s></s> \n",
      "\n",
      "<s> x the adventure of  the  speckled  band  ix  </s> </s> \n",
      "\n",
      "<s> holmes i said you  have  drawn  a  net  round  this  man  from  which  he  cannot  escape </s> \n",
      "\n",
      "<s> any alternate format must  include  the  full  project  gutenberg  tm  license  must  appear  prominently  whenever  any </s> \n",
      "\n",
      "<s> old turner lived for  seven  months  after  our  interview  but  he  is  now  dead  and  there </s> \n",
      "\n",
      "<s> special rules set forth  in  the  general  terms  of  use  and  redistributing  project  gutenberg  tm  electronic </s> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def Gen_Sentence(model_name):\n",
    "    print(\"*********************Generating Random sentences based on\", model_name, \"***********************\\n\")\n",
    "    if (model_name == \"unigram\"):\n",
    "        for i in range(0,8):\n",
    "            new = \"\"\n",
    "            sen_gen = '<s>'\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = unigram_dictt\n",
    "                if subdict:\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "            \n",
    "    if model_name == \"bigram\":\n",
    "        for i in range(0,8):\n",
    "            prev_word =\"<s>\" \n",
    "            new = \"\"\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = bigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    new= random.choice(list(subdict))\n",
    "                prev_word = new\n",
    "                sen_gen = sen_gen + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "\n",
    "        \n",
    "    if model_name == \"trigram\":\n",
    "         for i in range(0,8):\n",
    "            temp='<s>'\n",
    "            new =  random.choice(list(bigram_dictt.get(temp)))\n",
    "            prev_word = temp + \" \" + new\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = trigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    temp = new\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new + \" \" \n",
    "                prev_word = temp + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "    if model_name == \"quadrigram\":\n",
    "        for i in range(0,8):\n",
    "            temp1='<s>'\n",
    "            temp2 =  random.choice(list(bigram_dictt.get(temp1)))\n",
    "            new =  random.choice(list(trigram_dictt.get(temp1 + \" \" + temp2)))\n",
    "            prev_word = temp1 + \" \" + temp2 + \" \" + new\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = quadrigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    temp1 = temp2\n",
    "                    temp2 = new\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new + \" \" \n",
    "                prev_word = temp1 +  \" \" + temp2 + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "    if model_name == \"pentigram\":\n",
    "        for i in range(0,8):\n",
    "            temp1='<s>'\n",
    "            temp2 =  random.choice(list(bigram_dictt.get(temp1)))\n",
    "            temp3 =  random.choice(list(trigram_dictt.get(temp1 + \" \" + temp2)))\n",
    "            new =   random.choice(list(quadrigram_dictt.get(temp1 + \" \" + temp2 + \" \" + temp3)))\n",
    "            prev_word = temp1 + \" \" + temp2 + \" \" +temp3 + \" \"+ new\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = pentigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    temp1 = temp2\n",
    "                    temp2 = temp3\n",
    "                    temp3 = new\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new + \" \" \n",
    "                prev_word = temp1 +  \" \" + temp2 + \" \" + temp3 +\" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "\n",
    "        \n",
    "model = [ 'unigram', 'bigram', 'trigram', 'quadrigram', 'pentigram']\n",
    "for modd in model:\n",
    "    build_dictionary(modd)\n",
    "    Gen_Sentence (modd)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed value of d for good turing= 0.8707390797480395\n"
     ]
    }
   ],
   "source": [
    "#Caluclating d values for good turing\n",
    "\n",
    "countOfCounts = {}\n",
    "gd_count= {}\n",
    "def countOfCountsTable():\n",
    "    \n",
    "\n",
    "    count_list =  set(bigram_count.values())\n",
    "    countsOfCounts = {}\n",
    "    for c in count_list :\n",
    "        countOfCounts[c] = 0\n",
    "        for key, keycount in bigram_count.items():\n",
    "            if keycount == c:\n",
    "                countOfCounts[c] += 1\n",
    "    return countOfCounts\n",
    "\n",
    "\n",
    "countOfCounts = countOfCountsTable()\n",
    "N=sum(list(bigram_count.values()))\n",
    "dist = len(bigram_count.values())\n",
    "N_0 = (len(unigram_count) * len(unigram_count)) - dist\n",
    "# print(\"Bigrams seen =\", N)\n",
    "# print(\"distinct Bigrams\", dist)\n",
    "# print(\"Bigrams not seen\", N_0)\n",
    "\n",
    "\n",
    "gd_count [0] = countOfCounts[1] / N\n",
    "countOfCounts[0] =N_0\n",
    "d =0 \n",
    "for i in range(1,10):     #max(countOfCounts)\n",
    "    gd_count[i] = ((i+1) * countOfCounts[i+1]) /countOfCounts [i]\n",
    "    \n",
    "# print(\"Updated count values of bigrams corresponding to each original count is mentioned in key value pair\")\n",
    "\n",
    "for i in range (1,7):\n",
    "    d = d +(i - gd_count[i])\n",
    "#     print(i, gd_count[i])\n",
    "d= d/6\n",
    "print(\"Observed value of d for good turing=\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating  Smooth probabilities Add1 and Good Turing\n",
    "bigram_prob_smooth = {}\n",
    "bigram_count_smooth = {}\n",
    "bigram_prob_gd = {}\n",
    "bigram_count_gd = {}\n",
    "\n",
    "\n",
    "for key in bigram_count:\n",
    "    uniword = key.split(' ')\n",
    "#     print(uniword[0])\n",
    "#     print(key)\n",
    "    if (bigram_count[key] == 0):\n",
    "        bigram_prob[key] =0\n",
    "        bigram_prob_smooth[key] = 0\n",
    "#         print(\"P making  0\")\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        ######Calculating Add 1 Smoothed count and probability#############\n",
    "        \n",
    "        smooth = (bigram_count.get(key) + 1) / (unigram_count.get(uniword[0]) + (len(unigram_count)))   \n",
    "        #Adding one to each word and dividing by vocaulary size for updating the count\n",
    "        bigram_prob_smooth[key] = round (smooth, 6)     #Updated probaility\n",
    "        bigram_count_smooth[key] = bigram_prob_smooth[key] * unigram_count[uniword[0]]    #Updated Add 1 smooth count\n",
    "        \n",
    "        ######Calculating Good Turing Smoothed count and probability#############\n",
    "        \n",
    "        bigram_count_gd[key] = bigram_count[key] - d    #Using observed d value for calculating updated gd count\n",
    "        \n",
    "        bigram_prob_gd[key] = ( bigram_count_gd[key] / unigram_count[uniword[0]])   #Calulating probability with updated mle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sentence from thetest dataset = <s> i asked </s>\n",
      "Probability with unigram, = (Unsmoothed) 5.51693614128e-08\n",
      "Probability with bigram, = (Unsmoothed) 0.000528774251444\n",
      "Probability with trigram, = (Unsmoothed) 0.010787655116\n",
      "Probability with quadrigram, = (Unsmoothed) 0.611111\n",
      "Probability with pentigram, = (Unsmoothed) 1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculating Probability of a given sentence with some specific model\n",
    "import math as calc\n",
    "\n",
    "def probability(sentence, model_name):\n",
    "    P= 0\n",
    "    sent_words = sentence.lower().split(' ')\n",
    "    if model_name == 'unigram':\n",
    "      \n",
    "        for item in sent_words:\n",
    "            if item in unigram_prob:\n",
    "                P = P + calc.log(unigram_prob[item]) \n",
    "        return P\n",
    "    \n",
    "    elif model_name == 'bigram':\n",
    "        sent_biword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-1:\n",
    "                break\n",
    "            sent_biword.append(item+' '+sent_words[index+1])\n",
    "        for item in sent_biword:\n",
    "            if item in bigram_prob:\n",
    "                P = P +calc.log(bigram_prob[item])\n",
    "        return P\n",
    "    \n",
    "    elif model_name == 'add1':\n",
    "        sent_biword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-1:\n",
    "                break\n",
    "            sent_biword.append(item+' '+sent_words[index+1])\n",
    "        for item in sent_biword:\n",
    "            if item in bigram_prob_smooth:\n",
    "                P_ = P +calc.log(bigram_prob_smooth[item])\n",
    "        return P\n",
    "    elif model_name == 'gd':\n",
    "        sent_biword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-1:\n",
    "                break\n",
    "            sent_biword.append(item+' '+sent_words[index+1])\n",
    "        for item in sent_biword:\n",
    "            if item in bigram_prob_gd:\n",
    "#                 print(item, bigram_prob[item])\n",
    "                P = P +calc.log(bigram_prob_gd[item])\n",
    "        return P\n",
    "    elif model_name == 'trigram':\n",
    "        sent_triword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-2:\n",
    "                break\n",
    "            sent_triword.append(item+' '+sent_words[index+1]+' '+sent_words[index+2])\n",
    "        for item in sent_triword:\n",
    "            if item in trigram_prob:\n",
    "                P = P + calc.log(trigram_prob[item])\n",
    "        return P\n",
    "    elif model_name == 'quadrigram':\n",
    "        sent_quadriword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-3:\n",
    "                break\n",
    "            sent_quadriword.append(item+' '+sent_words[index+1]+' '+sent_words[index+2]+' '+sent_words[index+3])\n",
    "        for item in sent_quadriword:\n",
    "            if item in quadrigram_prob:\n",
    "                P = P + calc.log(quadrigram_prob[item])\n",
    "        return P\n",
    "    elif model_name == 'pentigram':\n",
    "        sent_pentiword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-4:\n",
    "                break\n",
    "            sent_pentiword.append(item+' '+sent_words[index+1]+' '+sent_words[index+2]+' '+sent_words[index+3]+' '+sent_words[index+4])\n",
    "        for item in sent_pentiword:\n",
    "            if item in pentigram_prob:\n",
    "                P = P + calc.log(pentigram_prob[item])\n",
    "        return P\n",
    "    \n",
    "    \n",
    "from random import randint\n",
    "sent = test[randint(0, len(test)-1)]    # Randomly picking the sentence from test data set\n",
    "print (\"Random sentence from thetest dataset =\", sent)\n",
    "P  = probability(sent, \"unigram\")\n",
    "print(\"Probability with unigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "P = probability(sent, \"bigram\")\n",
    "print(\"Probability with bigram, = (Unsmoothed)\"  ,np.exp(P))\n",
    "P  = probability(sent, \"trigram\")\n",
    "print(\"Probability with trigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "P  =probability(sent, \"quadrigram\")\n",
    "print(\"Probability with quadrigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "P  =probability(sent, \"pentigram\")\n",
    "print(\"Probability with pentigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating  Smooth probabilities Add1 and Good Turing\n",
    "bigram_prob_smooth = {}\n",
    "bigram_count_smooth = {}\n",
    "bigram_prob_gd = {}\n",
    "bigram_count_gd = {}\n",
    "\n",
    "\n",
    "for key in bigram_count:\n",
    "    uniword = key.split(' ')\n",
    "#     print(uniword[0])\n",
    "#     print(key)\n",
    "    if (bigram_count[key] == 0):\n",
    "        bigram_prob_smooth[key] = 0\n",
    "    else:\n",
    "        bigram_prob[key] = round( bigram_count.get(key) / float(unigram_count.get(uniword[0])), 6)\n",
    "        smooth = (bigram_count.get(key) + 1) / float(unigram_count.get(uniword[0]) + (len(bigram_count)))\n",
    "        ######Calculating Add 1 Smoothed count and probability#############\n",
    "        bigram_prob_smooth[key] = round (smooth, 6)\n",
    "        bigram_count_smooth[key] = bigram_prob_smooth[key] * unigram_count[uniword[0]]\n",
    "        \n",
    "        ######Calculating Good Turing Smoothed count and probability#############\n",
    "        \n",
    "        bigram_count_gd[key] = bigram_count[key] - d\n",
    "        \n",
    "        bigram_prob_gd[key] = ( bigram_count_gd[key] / unigram_count[uniword[0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsmoothed Count ' to step ' =  3\n",
      "Smoothed Count ' to step '= 0.20063999999999999\n",
      "Unsmoothed Count ' were alone ' =  1\n",
      "Smoothed Count ' were alone '= 0.01288\n",
      "Unsmoothed Count ' saw that ' =  10\n",
      "Smoothed Count ' saw that '= 0.018105000000000003\n",
      "Unsmoothed Count ' deepest moment ' =  1\n",
      "Smoothed Count ' deepest moment '= 0.000184\n",
      "Unsmoothed Count ' him </s> ' =  93\n",
      "Smoothed Count ' him </s> '= 0.738947\n",
      "Unsmoothed Count ' sentimental considerations ' =  1\n",
      "Smoothed Count ' sentimental considerations '= 4.6e-05\n",
      "Unsmoothed Count ' a ring ' =  6\n",
      "Smoothed Count ' a ring '= 0.33759\n",
      "Unsmoothed Count ' now definitely ' =  1\n",
      "Smoothed Count ' now definitely '= 0.00897\n",
      "Unsmoothed Count ' an inn ' =  1\n",
      "Smoothed Count ' an inn '= 0.012696\n",
      "Unsmoothed Count ' dreary experience ' =  1\n",
      "Smoothed Count ' dreary experience '= 4.6e-05\n",
      "As we can see, there is huge reduction in the number of counts of particular bigrams, When we do Add-one Smoothing.This happens because we have distributed the probability mass of existing bigrams to the bigrams which do not exist in thecorpus. So we have to reduce the probability of already existing bigrams and hence the their count gets decreased, but, so huge reduction of count is not desirable. Therefore Add 1 smoothing is not a good solution for language modelling. \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range (0, 10):\n",
    "    key =random.choice(list(bigram_count.keys()))\n",
    "    print(\"Unsmoothed Count '\", key, \"' = \", bigram_count[key])\n",
    "    print (\"Smoothed Count '\", key, \"'=\",  bigram_count_smooth[key])\n",
    "print(\"As we can see, there is huge reduction in the number of counts of particular bigrams, When we do Add-one Smoothing.\\\n",
    "This happens because we have distributed the probability mass of existing bigrams to the bigrams which do not exist in the\\\n",
    "corpus. So we have to reduce the probability of already existing bigrams and hence the their count gets decreased, but, so \\\n",
    "huge reduction of count is not desirable. Therefore Add 1 smoothing is not a good solution for language modelling. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sentence from the test = <s> there is mortimers the tobacconist the little newspaper shop the coburg branch of the city and suburban bank the vegetarian restaurant and mcfarlanes carriage building depot </s>\n",
      "Perplexity ,add1 = 1.0\n",
      "Perplexity ,Good Turing = 0.905391292327\n"
     ]
    }
   ],
   "source": [
    "def perplexity(sent):\n",
    "   \n",
    "    print(\"Probability =\", P)\n",
    "    perp = pow(P, 1/float(len(sent))) \n",
    "    return perp\n",
    "\n",
    "\n",
    "\n",
    "from random import randint\n",
    "sent = test[randint(0, len(test)-1)]    # Randomly picking the sentence from test data set\n",
    "print (\"Random sentence from the test =\", sent)\n",
    "\n",
    "prob = probability(sent, \"add1\")\n",
    "prob =np.exp(prob)\n",
    "perp = pow(prob, 1/float(len(sent))) \n",
    "print(\"Perplexity ,add1 =\",  perp )\n",
    "\n",
    "\n",
    "prob = probability(sent, \"gd\")\n",
    "prob =np.exp(prob)\n",
    "perp = pow(prob, 1/float(len(sent))) \n",
    "print(\"Perplexity ,Good Turing =\",  perp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load text from Project Gutenberg URL\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "url_template = 'http://www.gutenberg.org/cache/epub/1661/pg1661.txt'\n",
    "f = urllib.request.urlopen(url_template)\n",
    "text = f.read().decode(\"utf-8\") \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pre- Processing Part\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# Preprocessing part\n",
    "text=text.replace('\\n', ' ')\n",
    "text=text.replace('\"s', ' ')\n",
    "text=text.replace(',', ' ')\n",
    "text=text.replace('/s', ' ')\n",
    "text=text.replace('\"', ' ')\n",
    "text=text.replace (\"'\", '')\n",
    "text = text.lower()\n",
    "# text= re.sub('[(){}<>] ', ' ', text)\n",
    "\n",
    "sent_tokenize_list = sent_tokenize(text)\n",
    "# print(len(sent_tokenize_list))\n",
    "sent_start_end = []\n",
    "words = []\n",
    "\n",
    "# print(sent_tokenize_list)\n",
    "\n",
    "for sent in sent_tokenize_list:\n",
    "    sent = ' '.join(('<s>',sent,'</s>'))\n",
    "    sent = sent.replace('!', ' ')\n",
    "    sent = sent.replace('.', ' ')\n",
    "    sent = sent.replace('?', ' ')\n",
    "    sent = sent.replace('-', ' ')\n",
    "    sent = sent.replace('ï»¿', ' ')\n",
    "    sent = sent.replace('*', ' ')   \n",
    "    sent = sent.replace('\\n', ' ') \n",
    "    sent = sent.replace(':', ' ') \n",
    "    sent = sent.replace(';', ' ')    \n",
    "    \n",
    "#     sent = str(TextBlob(sent).correct())          \n",
    "    sent = re.sub( '\\s{2,}', ' ', sent).strip()    #Trying to remove extra spaces from sent\n",
    "#     print(sent)\n",
    "    for word in sent.split(' '):\n",
    "        words.append(word)     #Words List\n",
    "    sent_start_end.append(sent)  \n",
    "# print(sent_start_end[500:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens =  122392\n"
     ]
    }
   ],
   "source": [
    "# print(words [500:1000])\n",
    "print(\"Total Tokens = \", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting the file into 80% and 20%\n",
    "train, test = train_test_split(sent_start_end, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training token count 98049\n"
     ]
    }
   ],
   "source": [
    "word_train = []\n",
    "for sent in train:\n",
    "    for word in sent.split(' '):\n",
    "        word_train.append(word)                  #Training set words list\n",
    "print(\"Training token count\" , len(word_train))\n",
    "# print(word_train[69000:70000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing token count 24343\n"
     ]
    }
   ],
   "source": [
    "word_test = []\n",
    "for sent in test:\n",
    "    for word in sent.split(' '):\n",
    "        word_test.append(word)                  #Testing set words list\n",
    "print(\" Testing token count\", len(word_test))\n",
    "# print(word_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training token Count (seen) = 98049\n",
      "Distinct Unigrams count = 7529\n",
      "Expected Unigrams Count =  7529\n",
      "Top 10 MLE for unigram\n",
      "[('<s>', 0.056115), ('</s>', 0.056115), ('the', 0.047731), ('and', 0.025039), ('i', 0.02408), ('to', 0.022958), ('of', 0.022703), ('a', 0.022152), ('in', 0.015033), ('it', 0.014319)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "unigram_count=Counter(word_train)\n",
    "\n",
    "#MLE Probabilities of unigram\n",
    "sum2 = 0\n",
    "for key in unigram_count:\n",
    "    sum2 = float(sum2 + unigram_count.get(key))\n",
    "\n",
    "unigram_prob = {}\n",
    "for key in unigram_count:\n",
    "    unigram_prob[key] = round( unigram_count.get(key) / sum2, 6)\n",
    "\n",
    "#Displaying the results for unigrams\n",
    "print(\"Total training token Count (seen) =\" , len(word_train))\n",
    "# print(\"Distict Tokens = \", len(set(word_train)))\n",
    "print(\"Distinct Unigrams count =\", len(unigram_count))\n",
    "print(\"Expected Unigrams Count = \", len(unigram_count)   )\n",
    "gram1 = sorted(unigram_prob.items(), key=lambda count: count[1], reverse =True)\n",
    "print(\"Top 10 MLE for unigram\")\n",
    "print (gram1[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training bigram count (seen) = 98048\n",
      "Corpus Training bigram count (distinct) = 43136\n",
      "Expected Training bigram Count (distinct) =  56685841\n",
      "Top 10 MLE for bigram\n",
      "[('<s> fine', 0.000182), ('<s> stay', 0.000182), ('<s> hudson', 0.000182), ('<s> im', 0.000182), ('<s> step', 0.000182), ('<s> filled', 0.000182), ('<s> therein', 0.000182), ('<s> anybody', 0.000182), ('<s> boone', 0.000182), ('<s> deserted', 0.000182)]\n"
     ]
    }
   ],
   "source": [
    "####Bigram tokens\n",
    "\n",
    "biwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-1:\n",
    "        break\n",
    "    biwords.append(item+' '+word_train[index+1])\n",
    "# print(biwords)\n",
    "bigram_count = Counter(biwords)\n",
    "\n",
    "# Bigram Probabilities with and without smoothing\n",
    "bigram_prob = {}\n",
    "for key in bigram_count:\n",
    "    uniword = key.split(' ')\n",
    "#     print(uniword[0])\n",
    "#     print(key)\n",
    "    if (bigram_count[key] == 0):\n",
    "        bigram_prob[key] =0\n",
    "        bigram_prob_smooth[key] = 0\n",
    "    else:\n",
    "        bigram_prob[key] = round( bigram_count.get(key) / float(unigram_count.get(uniword[0])), 6)\n",
    "print(\"Corpus Training bigram count (seen) =\", sum(list(bigram_count.values())))\n",
    "print(\"Corpus Training bigram count (distinct) =\", len(bigram_count))\n",
    "print(\"Expected Training bigram Count (distinct) = \", (len(unigram_count) * len(unigram_count)))  \n",
    "\n",
    "#displaying Probabilities for bigram\n",
    "gram2 = sorted(bigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Top 10 MLE for bigram\")\n",
    "print (gram2[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training trigram count (seen) = 98047\n",
      "Corpus Training trigram count (distinct) = 74275\n",
      "Training Expected trigrams Count (distinct) =  426787696889\n",
      "Least 10 MLE for trigram\n",
      "[('</s> <s> fine', 0.000182), ('</s> <s> stay', 0.000182), ('</s> <s> hudson', 0.000182), ('</s> <s> im', 0.000182), ('</s> <s> step', 0.000182), ('</s> <s> filled', 0.000182), ('</s> <s> therein', 0.000182), ('</s> <s> anybody', 0.000182), ('</s> <s> boone', 0.000182), ('</s> <s> deserted', 0.000182)]\n"
     ]
    }
   ],
   "source": [
    "####Trigram Tokens\n",
    "triwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-2:\n",
    "        break\n",
    "    triwords.append(item+' '+word_train[index+1]+' '+word_train[index+2])\n",
    "trigram_count = Counter(triwords)\n",
    "\n",
    "trigram_prob = {}\n",
    "for key in trigram_count:\n",
    "    biword = key.split(' ')\n",
    "    trigram_prob[key] = round( trigram_count.get(key) / bigram_count.get(biword[0] +' ' + biword[1]), 6)\n",
    "\n",
    "\n",
    "print(\"Corpus Training trigram count (seen) =\", sum(list(trigram_count.values())))\n",
    "print(\"Corpus Training trigram count (distinct) =\", len(trigram_count))\n",
    "print(\"Training Expected trigrams Count (distinct) = \", len(unigram_count) * len(unigram_count) * len(unigram_count)   )\n",
    "\n",
    "gram3 = sorted(trigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Least 10 MLE for trigram\")\n",
    "print (gram3[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training quadrigram count (seen) = 98046\n",
      "Corpus Training quadrigram count (distinct) = 89302\n",
      "Expected quadrigrams Count (distinct) =  3213284569877281\n",
      "Least 10 MLE for quadrigram\n",
      "[('</s> <s> i promise', 0.001272), ('</s> <s> i struck', 0.001272), ('</s> <s> i lent', 0.001272), ('</s> <s> i exclaimed', 0.001272), ('</s> <s> i already', 0.001272), ('</s> <s> i observe', 0.001272), ('</s> <s> i wired', 0.001272), ('</s> <s> i caught', 0.001272), ('</s> <s> i deduced', 0.001272), ('</s> <s> i guessed', 0.001272)]\n"
     ]
    }
   ],
   "source": [
    "####Quadrigram Tokens\n",
    "\n",
    "quadriwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-3:\n",
    "        break\n",
    "    quadriwords.append(item+' '+word_train[index+1]+' '+word_train[index+2]+' '+word_train[index+3])\n",
    "quadrigram_count = Counter(quadriwords)\n",
    "# print(quadrigram_count)\n",
    "\n",
    "quadrigram_prob = {}\n",
    "for key in quadrigram_count:\n",
    "    triword = key.split(' ')\n",
    "#     print(triword[0:3])\n",
    "#     print(key)\n",
    "    quadrigram_prob[key] = round( quadrigram_count.get(key) / trigram_count.get(triword[0] +' ' + triword[1]+' ' + triword[2]), 6)\n",
    "# print(quadrigram_prob)\n",
    "\n",
    "print(\"Corpus Training quadrigram count (seen) =\", sum(list(quadrigram_count.values())))\n",
    "print(\"Corpus Training quadrigram count (distinct) =\", len(quadrigram_count))\n",
    "print(\"Expected quadrigrams Count (distinct) = \", len(unigram_count) * len(unigram_count) * len(unigram_count)  * len(unigram_count)  )\n",
    "\n",
    "gram4 = sorted(quadrigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Least 10 MLE for quadrigram\")\n",
    "print (gram4[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training pentigram count (seen) = 98045\n",
      "Corpus Training pentigram count (distinct) = 95355\n",
      "Expected pentigrams Count =  24192819526606048649\n",
      "Least 10 MLE for pentigram\n",
      "[('</s> <s> it is only', 0.007042), ('</s> <s> it is nearly', 0.007042), ('</s> <s> it is introspective', 0.007042), ('</s> <s> it is fortunate', 0.007042), ('</s> <s> it is certain', 0.007042), ('</s> <s> it is thought', 0.007042), ('</s> <s> it is evidently', 0.007042), ('</s> <s> it is wednesday', 0.007042), ('</s> <s> it is straight', 0.007042), ('</s> <s> it is simplicity', 0.007042)]\n"
     ]
    }
   ],
   "source": [
    "####Pentigram Tokens\n",
    "\n",
    "pentiwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-4:\n",
    "        break\n",
    "    pentiwords.append(item+' '+word_train[index+1]+' '+word_train[index+2]+' '+word_train[index+3]+' '+word_train[index+4])\n",
    "pentigram_count = Counter(pentiwords)\n",
    "# print(pentigram_count)\n",
    "\n",
    "pentigram_prob = {}\n",
    "for key in pentigram_count:\n",
    "    quadriword = key.split(' ')\n",
    "#     print(quadriword[0:4])\n",
    "#     print(key)\n",
    "    pentigram_prob[key] = round( pentigram_count.get(key) / quadrigram_count.get(quadriword[0] +' ' + quadriword[1]+' ' + quadriword[2]+' ' + quadriword[3]), 6)\n",
    "# print(pentigram_prob)\n",
    "\n",
    "print(\"Corpus Training pentigram count (seen) =\", sum(list(pentigram_count.values())))\n",
    "print(\"Corpus Training pentigram count (distinct) =\", len(pentigram_count))\n",
    "print(\"Expected pentigrams Count = \", len(unigram_count) * len(unigram_count) * len(unigram_count)  * len(unigram_count) * len(unigram_count)  )\n",
    "\n",
    "gram5 = sorted(pentigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Least 10 MLE for pentigram\")\n",
    "print (gram5[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Building nested dictionary \n",
    "import random\n",
    "unigram_dictt = {}\n",
    "bigram_dictt = {}\n",
    "trigram_dictt = {}\n",
    "quadrigram_dictt = {}\n",
    "pentigram_dictt = {}\n",
    "def build_dictionary(model):\n",
    "    if model == \"unigram\":\n",
    "#         print(\"Unigram Dictionary\")\n",
    "        for i in range(len(words)): \n",
    "            if not unigram_dictt.get(words[i]): \n",
    "                unigram_dictt[words[i]] = 1 \n",
    "            else: \n",
    "                unigram_dictt[words[i]] += 1 \n",
    "        summ = sum (unigram_dictt.values())\n",
    "\n",
    "        for key in unigram_dictt:\n",
    "            prob =round(unigram_dictt.get(key) / summ,6)\n",
    "            unigram_dictt[key] = prob\n",
    "\n",
    "\n",
    "        gram1_iter= iter(unigram_dictt)\n",
    "\n",
    "        \n",
    "    if model == \"bigram\":\n",
    "#         print(\"bigram dictionary\")\n",
    "        for i in range(len(words) - 1): \n",
    "            if not bigram_dictt.get(words[i]): \n",
    "                bigram_dictt[words[i]] = {} \n",
    "            if not bigram_dictt[words[i]].get(words[i+1]): \n",
    "                bigram_dictt[words[i]][words[i+1]] = 1 \n",
    "            else: \n",
    "                bigram_dictt[words[i]][words[i+1]] += 1 \n",
    "        for outer_key in bigram_dictt:\n",
    "            subdict = dict(bigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                bigram_dictt[outer_key][inner_key] = prob\n",
    "        gram2_iter= iter(bigram_dictt)\n",
    "\n",
    "\n",
    "    elif model == \"trigram\":  \n",
    "#         print(\"trigram ditionary\")\n",
    "        for i in range(len(words) - 2): \n",
    "            if not trigram_dictt.get(words[i] + ' ' + words[i+1]): \n",
    "                trigram_dictt[words[i] + ' ' + words[i+1]] = {} \n",
    "            if not trigram_dictt[words[i] + ' ' + words[i+1]].get(words[i+2]): \n",
    "                trigram_dictt[words[i] + ' ' + words[i+1]][words[i+2]] = 1 \n",
    "            else: \n",
    "                trigram_dictt[words[i] + ' ' + words[i+1]][words[i+2]] += 1 \n",
    "    \n",
    "        for outer_key in trigram_dictt:\n",
    "            subdict = dict(trigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                trigram_dictt[outer_key][inner_key] = prob\n",
    "                \n",
    "    \n",
    "        gram3_iter= iter(trigram_dictt)\n",
    "\n",
    "        \n",
    "    elif model == \"quadrigram\":\n",
    "#         print(\"quadrigram dictionary\")\n",
    "        for i in range(len(words) - 3): \n",
    "            if not quadrigram_dictt.get(words[i] + ' ' + words[i+1] + ' ' + words [i+2]): \n",
    "                quadrigram_dictt[words[i] + ' ' + words[i+1]+ ' ' + words[i+2]] = {} \n",
    "            if not quadrigram_dictt[words[i] + ' ' + words[i+1] +' ' + words[i+2]].get(words[i+3]): \n",
    "                quadrigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]][words[i+3]] = 1 \n",
    "            else: \n",
    "                quadrigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]][words[i+3]] += 1 \n",
    "        for outer_key in quadrigram_dictt:\n",
    "            subdict = dict(quadrigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                quadrigram_dictt[outer_key][inner_key] = prob\n",
    "        gram4_iter= iter(quadrigram_dictt)\n",
    "\n",
    "\n",
    "    elif model == \"pentigram\":\n",
    "#         print(\"pentigram dictionary\")\n",
    "        for i in range(len(words) - 4): \n",
    "            if not pentigram_dictt.get(words[i] + ' ' + words[i+1] + ' ' + words [i+2]+ ' ' + words [i+3]): \n",
    "                pentigram_dictt[words[i] + ' ' + words[i+1]+ ' ' + words[i+2]+ ' ' + words [i+3]] = {} \n",
    "            if not pentigram_dictt[words[i] + ' ' + words[i+1] +' ' + words[i+2]+ ' ' + words [i+3]].get(words[i+4]): \n",
    "                pentigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]+ ' ' + words [i+3]][words[i+4]] = 1 \n",
    "            else: \n",
    "                pentigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]+ ' ' + words [i+3]][words[i+4]] += 1 \n",
    "        for outer_key in pentigram_dictt:\n",
    "            subdict = dict(pentigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                pentigram_dictt[outer_key][inner_key] = prob\n",
    "        gram5_iter= iter(pentigram_dictt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Generating Random sentences based on unigram ***********************\n",
      "\n",
      "<s> shabbily overjoyed inconvenience imperilled oclock figures philadelphia darted indian supply investigation inheritance simplify ventured ungovernable line hastening engaging lead window relative poisoning putting shuddered tresses undue sailing tugged consult</s> \n",
      "\n",
      "<s> ascii slabs typewrite twitter cleared contents adapt taketh outskirts handy readable glisten haired barque greenwich disjecta slide smudge gravity fond another holder) barrow choose shelves ought splashing hebrew peep</s> \n",
      "\n",
      "<s> bands process mirror tendencies diggings interjected practice quotes affect bulge spine official vanish lodging furnished owed insects neighbouring weakness against yellow stop peculiarities summer faddy registry receive fought eliminated</s> \n",
      "\n",
      "<s> smasher mail lawn various increasing plentiful arrangements assault arms limps thursday changing setting consideration seven secured fishes wagon firemen badly lure blew trafalgar commander sky sorry representations collapsed filed</s> \n",
      "\n",
      "<s> rattle acquiesce parish expensive cunning audible it receipts shoots determination interview widow describes passage electronic sluggishly grown heading telephone felony assizes drinking locations apologise washing gipsy (if hanover wants</s> \n",
      "\n",
      "<s> acquire midway returning investments tells fattest decrepit mens financial unpleasantness homely silently eddy captured blowing wound observer immediate discretion independent broadened grown bandy genii tumultuously implicates branches strikes activity</s> \n",
      "\n",
      "<s> travellers occurrences competition seats page consultations stained laws strongly circles now hatty stool slung ix lose arresting roughly learned park working hunt seaports being cobb rural parietal compress try</s> \n",
      "\n",
      "<s> crowd kings dived scent community thirty thought vessels actions cap downstairs ways hear sings stuffed relapsing abound pets cure tramped saluted shutter ($1 manifested stammered saturdays government enemys apart</s> \n",
      "\n",
      "*********************Generating Random sentences based on bigram ***********************\n",
      "\n",
      "<s> heres the exalted names are screening your pal what it difficult but look here sir said on looking earnestly </s></s> \n",
      "\n",
      "<s> upon these are engaged said very happy and borrowed for j o the defending counsel </s></s> \n",
      "\n",
      "<s> running down four fingers it always about lord st pauls </s></s> \n",
      "\n",
      "<s> retired from comparing notes upon bohemian nobleman </s></s> \n",
      "\n",
      "<s> indemnity you bring up beside this hat is country surgeon </s></s> \n",
      "\n",
      "<s> smack </s></s> \n",
      "\n",
      "<s> 2 </s></s> \n",
      "\n",
      "<s> pon my breath for any positive intention of dates as likely not a perplexing position forever a widespread rumours as keen a fear and ordered fresh clue could learn</s> \n",
      "\n",
      "*********************Generating Random sentences based on trigram ***********************\n",
      "\n",
      "<s> voilà tout  </s> </s> \n",
      "\n",
      "<s> pending the  alterations  as  i  expected  lounging  about  his  quarrel  with  his  hat  in  his </s> \n",
      "\n",
      "<s> finally i  went  home  to  saxe  coburg  square  presented  as  great  a  length  by  telling </s> \n",
      "\n",
      "<s> faces to  the  passage  </s> </s> \n",
      "\n",
      "<s> recently he  has  frequently  brought  him  the  sympathy  of  the  inner  temple  </s> </s> \n",
      "\n",
      "<s> had this  unfortunate  lady  died  of  then  </s> </s> \n",
      "\n",
      "<s> yet with  all  my  medical  instincts  </s> </s> \n",
      "\n",
      "<s> youd be  as  averse  to  a  marriage  was  arranged  then  for  the  servants  </s> </s> \n",
      "\n",
      "*********************Generating Random sentences based on quadrigram ***********************\n",
      "\n",
      "<s> six out and  six  back  </s> </s> \n",
      "\n",
      "<s> posted to day  </s> </s> \n",
      "\n",
      "<s> imagine then my  thrill  of  terror  when  last  night  as  i  lay  awake  thinking  over  her </s> \n",
      "\n",
      "<s> pooh pooh </s> </s> \n",
      "\n",
      "<s> heh </s></s> \n",
      "\n",
      "<s> hullo </s></s> \n",
      "\n",
      "<s> astonishment at the  unexpected  sight  of  you  might  cause  him  to  throw  up  his  hands  </s> </s> \n",
      "\n",
      "<s> very right </s> </s> \n",
      "\n",
      "*********************Generating Random sentences based on pentigram ***********************\n",
      "\n",
      "<s> palmer and pritchard were  among  the  heads  of  their  profession  </s> </s> \n",
      "\n",
      "<s> men who had only  known  the  quiet  thinker  and  logician  of  baker  street  would  have  failed </s> \n",
      "\n",
      "<s> twice burglars in my  pay  ransacked  her  house  </s> </s> \n",
      "\n",
      "<s> cocktail 1s </s></s> \n",
      "\n",
      "<s> project gutenberg is a  registered  trademark  and  may  not  be  used  if  you  charge  for  the </s> \n",
      "\n",
      "<s> for christs sake dont  </s> </s> \n",
      "\n",
      "<s> coming on the top  of  a  harmonium  beside  the  door  </s> </s> \n",
      "\n",
      "<s> however when our turn  came  the  little  man  was  much  more  favourable  to  me  than  to </s> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def Gen_Sentence(model_name):\n",
    "    print(\"*********************Generating Random sentences based on\", model_name, \"***********************\\n\")\n",
    "    if (model_name == \"unigram\"):\n",
    "        for i in range(0,8):\n",
    "            new = \"\"\n",
    "            sen_gen = '<s>'\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = unigram_dictt\n",
    "                if subdict:\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "            \n",
    "    if model_name == \"bigram\":\n",
    "        for i in range(0,8):\n",
    "            prev_word =\"<s>\" \n",
    "            new = \"\"\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = bigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    new= random.choice(list(subdict))\n",
    "                prev_word = new\n",
    "                sen_gen = sen_gen + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "\n",
    "        \n",
    "    if model_name == \"trigram\":\n",
    "         for i in range(0,8):\n",
    "            temp='<s>'\n",
    "            new =  random.choice(list(bigram_dictt.get(temp)))\n",
    "            prev_word = temp + \" \" + new\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = trigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    temp = new\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new + \" \" \n",
    "                prev_word = temp + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "    if model_name == \"quadrigram\":\n",
    "        for i in range(0,8):\n",
    "            temp1='<s>'\n",
    "            temp2 =  random.choice(list(bigram_dictt.get(temp1)))\n",
    "            new =  random.choice(list(trigram_dictt.get(temp1 + \" \" + temp2)))\n",
    "            prev_word = temp1 + \" \" + temp2 + \" \" + new\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = quadrigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    temp1 = temp2\n",
    "                    temp2 = new\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new + \" \" \n",
    "                prev_word = temp1 +  \" \" + temp2 + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "    if model_name == \"pentigram\":\n",
    "        for i in range(0,8):\n",
    "            temp1='<s>'\n",
    "            temp2 =  random.choice(list(bigram_dictt.get(temp1)))\n",
    "            temp3 =  random.choice(list(trigram_dictt.get(temp1 + \" \" + temp2)))\n",
    "            new =   random.choice(list(quadrigram_dictt.get(temp1 + \" \" + temp2 + \" \" + temp3)))\n",
    "            prev_word = temp1 + \" \" + temp2 + \" \" +temp3 + \" \"+ new\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = pentigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    temp1 = temp2\n",
    "                    temp2 = temp3\n",
    "                    temp3 = new\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new + \" \" \n",
    "                prev_word = temp1 +  \" \" + temp2 + \" \" + temp3 +\" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "\n",
    "        \n",
    "model = [ 'unigram', 'bigram', 'trigram', 'quadrigram', 'pentigram']\n",
    "for modd in model:\n",
    "    build_dictionary(modd)\n",
    "    Gen_Sentence (modd)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed value of d for good turing= 0.97\n"
     ]
    }
   ],
   "source": [
    "#Caluclating d values for good turing\n",
    "\n",
    "countOfCounts = {}\n",
    "gd_count= {}\n",
    "def countOfCountsTable():\n",
    "    \n",
    "\n",
    "    count_list =  set(bigram_count.values())\n",
    "    countsOfCounts = {}\n",
    "    for c in count_list :\n",
    "        countOfCounts[c] = 0\n",
    "        for key, keycount in bigram_count.items():\n",
    "            if keycount == c:\n",
    "                countOfCounts[c] += 1\n",
    "    return countOfCounts\n",
    "\n",
    "\n",
    "countOfCounts = countOfCountsTable()\n",
    "N=sum(list(bigram_count.values()))\n",
    "dist = len(bigram_count.values())\n",
    "N_0 = (len(unigram_count) * len(unigram_count)) - dist\n",
    "# print(\"Bigrams seen =\", N)\n",
    "# print(\"distinct Bigrams\", dist)\n",
    "# print(\"Bigrams not seen\", N_0)\n",
    "\n",
    "\n",
    "gd_count [0] = countOfCounts[1] / N\n",
    "countOfCounts[0] =N_0\n",
    "d =0 \n",
    "for i in range(1,10):     #max(countOfCounts)\n",
    "    gd_count[i] = ((i+1) * countOfCounts[i+1]) /countOfCounts [i]\n",
    "    \n",
    "# print(\"Updated count values of bigrams corresponding to each original count is mentioned in key value pair\")\n",
    "\n",
    "for i in range (1,7):\n",
    "    d = d +(i - gd_count[i])\n",
    "#     print(i, gd_count[i])\n",
    "d=  round(d/6, 2)\n",
    "print(\"Observed value of d for good turing=\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating  Smooth probabilities Add1 and Good Turing\n",
    "bigram_prob_smooth = {}\n",
    "bigram_count_smooth = {}\n",
    "bigram_prob_gd = {}\n",
    "bigram_count_gd = {}\n",
    "\n",
    "\n",
    "for key in bigram_count:\n",
    "    uniword = key.split(' ')\n",
    "#     print(uniword[0])\n",
    "#     print(key)\n",
    "        \n",
    "        ######Calculating Add 1 Smoothed count and probability#############\n",
    "        \n",
    "    smooth = (bigram_count.get(key) + 1) / (unigram_count.get(uniword[0]) + (len(unigram_count)))   \n",
    "    #Adding one to each word and dividing by vocaulary size for updating the count\n",
    "    bigram_prob_smooth[key] = round (smooth, 6)     #Updated probaility\n",
    "    bigram_count_smooth[key] = bigram_prob_smooth[key] * unigram_count[uniword[0]]    #Updated Add 1 smooth count\n",
    "    ######Calculating Good Turing Smoothed count and probability#############\n",
    "        \n",
    "    bigram_count_gd[key] = bigram_count[key] - d    #Using observed d value for calculating updated gd count\n",
    "        \n",
    "    bigram_prob_gd[key] = ( bigram_count_gd[key] / unigram_count[uniword[0]])   #Calulating probability with updated mle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating Probability of a given sentence with some specific model\n",
    "import math as calc\n",
    "\n",
    "def probability(sentence, model_name):\n",
    "    P= 0\n",
    "    sent_words = sentence.lower().split(' ')\n",
    "    if model_name == 'unigram':\n",
    "      \n",
    "        for item in sent_words:\n",
    "            if item in unigram_prob:\n",
    "                P = P + calc.log(unigram_prob[item]) \n",
    "        return P\n",
    "    \n",
    "    elif model_name == 'bigram':\n",
    "        sent_biword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-1:\n",
    "                break\n",
    "            sent_biword.append(item+' '+sent_words[index+1])\n",
    "        for item in sent_biword:\n",
    "            if item in bigram_prob:\n",
    "                P = P +calc.log(bigram_prob[item])\n",
    "        return P\n",
    "    \n",
    "    elif model_name == 'add1':\n",
    "        sent_biword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-1:\n",
    "                break\n",
    "            sent_biword.append(item+' '+sent_words[index+1])\n",
    "        for item in sent_biword:\n",
    "            if item in bigram_prob_smooth:\n",
    "                P = P +calc.log(bigram_prob_smooth[item])\n",
    "        return P\n",
    "    elif model_name == 'gd':\n",
    "        sent_biword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-1:\n",
    "                break\n",
    "            sent_biword.append(item+' '+sent_words[index+1])\n",
    "        for item in sent_biword:\n",
    "            if item in bigram_prob_gd:\n",
    "#                 print(item, bigram_prob[item])\n",
    "                P = P +calc.log(bigram_prob_gd[item])\n",
    "        return P\n",
    "    elif model_name == 'trigram':\n",
    "        sent_triword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-2:\n",
    "                break\n",
    "            sent_triword.append(item+' '+sent_words[index+1]+' '+sent_words[index+2])\n",
    "        for item in sent_triword:\n",
    "            if item in trigram_prob:\n",
    "                P = P + calc.log(trigram_prob[item])\n",
    "        return P\n",
    "    elif model_name == 'quadrigram':\n",
    "        sent_quadriword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-3:\n",
    "                break\n",
    "            sent_quadriword.append(item+' '+sent_words[index+1]+' '+sent_words[index+2]+' '+sent_words[index+3])\n",
    "        for item in sent_quadriword:\n",
    "            if item in quadrigram_prob:\n",
    "                P = P + calc.log(quadrigram_prob[item])\n",
    "        return P\n",
    "    elif model_name == 'pentigram':\n",
    "        sent_pentiword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-4:\n",
    "                break\n",
    "            sent_pentiword.append(item+' '+sent_words[index+1]+' '+sent_words[index+2]+' '+sent_words[index+3]+' '+sent_words[index+4])\n",
    "        for item in sent_pentiword:\n",
    "            if item in pentigram_prob:\n",
    "                P = P + calc.log(pentigram_prob[item])\n",
    "        return P\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sentence from thetest dataset = <s> your case is an exceedingly remarkable one and i shall be happy to look into it </s>\n",
      "Probability with unigram, = (Unsmoothed) 3.77230764946e-45\n",
      "Probability with bigram, = (Unsmoothed) 3.62312283996e-23\n",
      "Probability with trigram, = (Unsmoothed) 2.95216569025e-06\n",
      "Probability with quadrigram, = (Unsmoothed) 0.08333325\n",
      "Probability with pentigram, = (Unsmoothed) 1.0\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "sent = test[randint(0, len(test)-1)]    # Randomly picking the sentence from test data set\n",
    "print (\"Random sentence from thetest dataset =\", sent)\n",
    "P  = probability(sent, \"unigram\")\n",
    "print(\"Probability with unigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "P = probability(sent, \"bigram\")\n",
    "print(\"Probability with bigram, = (Unsmoothed)\"  ,np.exp(P))\n",
    "P  = probability(sent, \"trigram\")\n",
    "print(\"Probability with trigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "P  =probability(sent, \"quadrigram\")\n",
    "print(\"Probability with quadrigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "P  =probability(sent, \"pentigram\")\n",
    "print(\"Probability with pentigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsmoothed Count ' innocence </s> ' =  2\n",
      "Smoothed Count ' innocence </s> '= 0.0011940000000000002\n",
      "Unsmoothed Count ' regulations he ' =  1\n",
      "Smoothed Count ' regulations he '= 0.000266\n",
      "Unsmoothed Count ' third </s> ' =  1\n",
      "Smoothed Count ' third </s> '= 0.0037099999999999998\n",
      "Unsmoothed Count ' just where ' =  1\n",
      "Smoothed Count ' just where '= 0.027248\n",
      "Unsmoothed Count ' your fathers ' =  1\n",
      "Smoothed Count ' your fathers '= 0.081345\n",
      "Unsmoothed Count ' get these ' =  1\n",
      "Smoothed Count ' get these '= 0.013464\n",
      "Unsmoothed Count ' who was ' =  18\n",
      "Smoothed Count ' who was '= 0.52761\n",
      "Unsmoothed Count ' mccarthys feet ' =  1\n",
      "Smoothed Count ' mccarthys feet '= 0.0015899999999999998\n",
      "Unsmoothed Count ' say my ' =  1\n",
      "Smoothed Count ' say my '= 0.019725\n",
      "Unsmoothed Count ' this small ' =  1\n",
      "Smoothed Count ' this small '= 0.10584\n",
      "As we can see, there is huge reduction in the number of counts of particular bigrams, When we do Add-one Smoothing.This happens because we have distributed the probability mass of existing bigrams to the bigrams which do not exist in thecorpus. So we have to reduce the probability of already existing bigrams and hence the their count gets decreased, but, so huge reduction of count is not desirable. Therefore Add 1 smoothing is not a good solution for language modelling. \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range (0, 10):\n",
    "    key =random.choice(list(bigram_count.keys()))\n",
    "    print(\"Unsmoothed Count '\", key, \"' = \", bigram_count[key])\n",
    "    print (\"Smoothed Count '\", key, \"'=\",  bigram_count_smooth[key])\n",
    "print(\"As we can see, there is huge reduction in the number of counts of particular bigrams, When we do Add-one Smoothing.\\\n",
    "This happens because we have distributed the probability mass of existing bigrams to the bigrams which do not exist in the\\\n",
    "corpus. So we have to reduce the probability of already existing bigrams and hence the their count gets decreased, but, so \\\n",
    "huge reduction of count is not desirable. Therefore Add 1 smoothing is not a good solution for language modelling. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sentence from the test = <s> then again the introduction of his name will cause him to see it for everyone who knows him will direct his attention to it </s>\n",
      "Perplexity ,add1 = 2.13600076241\n",
      "Perplexity ,Good Turing = 1.84221531385\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "sent = test[randint(0, len(test)-1)]    # Randomly picking the sentence from test data set\n",
    "print (\"Random sentence from the test =\", sent)\n",
    "\n",
    "prob = probability(sent, \"add1\")\n",
    "prob =np.exp(prob)\n",
    "# print(\"Probability \", prob)\n",
    "perp = pow(prob, -(1/(len(sent)))) \n",
    "print(\"Perplexity ,add1 =\",  perp )\n",
    "\n",
    "\n",
    "prob = probability(sent, \"gd\")\n",
    "prob =np.exp(prob)\n",
    "perp = pow(prob, -(1/(len(sent)))) \n",
    "print(\"Perplexity ,Good Turing =\",  perp) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

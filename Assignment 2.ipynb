{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load text from Project Gutenberg URL\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "url_template = 'http://www.gutenberg.org/cache/epub/1661/pg1661.txt'\n",
    "f = urllib.request.urlopen(url_template)\n",
    "text = f.read().decode(\"utf-8\") \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pre- Processing Part\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# Preprocessing part\n",
    "text=text.replace('\\n', ' ')\n",
    "text=text.replace('\"s', ' ')\n",
    "text=text.replace(',', ' ')\n",
    "text=text.replace('/s', ' ')\n",
    "text=text.replace('\"', ' ')\n",
    "text=text.replace (\"'\", '')\n",
    "text = text.lower()\n",
    "# text= re.sub('[(){}<>] ', ' ', text)\n",
    "\n",
    "sent_tokenize_list = sent_tokenize(text)\n",
    "# print(len(sent_tokenize_list))\n",
    "sent_start_end = []\n",
    "words = []\n",
    "\n",
    "# print(sent_tokenize_list)\n",
    "\n",
    "for sent in sent_tokenize_list:\n",
    "    sent = ' '.join(('<s>',sent,'</s>'))\n",
    "    sent = sent.replace('!', ' ')\n",
    "    sent = sent.replace('.', ' ')\n",
    "    sent = sent.replace('?', ' ')\n",
    "    sent = sent.replace('-', ' ')\n",
    "    sent = sent.replace('ï»¿', ' ')\n",
    "    sent = sent.replace('*', ' ')   \n",
    "    sent = sent.replace('\\n', ' ') \n",
    "    sent = sent.replace(':', ' ') \n",
    "    sent = sent.replace(';', ' ')    \n",
    "    \n",
    "#     sent = str(TextBlob(sent).correct())          \n",
    "    sent = re.sub( '\\s{2,}', ' ', sent).strip()    #Trying to remove extra spaces from sent\n",
    "#     print(sent)\n",
    "    for word in sent.split(' '):\n",
    "        words.append(word)     #Words List\n",
    "    sent_start_end.append(sent)  \n",
    "# print(sent_start_end[500:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens =  122392\n"
     ]
    }
   ],
   "source": [
    "# print(words [500:1000])\n",
    "print(\"Total Tokens = \", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Splitting the file into 80% and 20%\n",
    "train, test = train_test_split(sent_start_end, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training token count 98514\n"
     ]
    }
   ],
   "source": [
    "word_train = []\n",
    "for sent in train:\n",
    "    for word in sent.split(' '):\n",
    "        word_train.append(word)                  #Training set words list\n",
    "print(\"Training token count\" , len(word_train))\n",
    "# print(word_train[69000:70000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Testing token count 23878\n"
     ]
    }
   ],
   "source": [
    "word_test = []\n",
    "for sent in test:\n",
    "    for word in sent.split(' '):\n",
    "        word_test.append(word)                  #Testing set words list\n",
    "print(\" Testing token count\", len(word_test))\n",
    "# print(word_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training token Count (seen) = 98514\n",
      "Distinct Unigrams count = 7569\n",
      "Expected Unigrams Count =  7569\n",
      "Top 10 MLE for unigram\n",
      "[('<s>', 0.05585), ('</s>', 0.05585), ('the', 0.047709), ('and', 0.02555), ('i', 0.024646), ('to', 0.023073), ('of', 0.022454), ('a', 0.02223), ('in', 0.014983), ('that', 0.014303)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "unigram_count=Counter(word_train)\n",
    "\n",
    "#MLE Probabilities of unigram\n",
    "sum2 = 0\n",
    "for key in unigram_count:\n",
    "    sum2 = float(sum2 + unigram_count.get(key))\n",
    "\n",
    "unigram_prob = {}\n",
    "for key in unigram_count:\n",
    "    unigram_prob[key] = round( unigram_count.get(key) / sum2, 6)\n",
    "\n",
    "#Displaying the results for unigrams\n",
    "print(\"Total training token Count (seen) =\" , len(word_train))\n",
    "# print(\"Distict Tokens = \", len(set(word_train)))\n",
    "print(\"Distinct Unigrams count =\", len(unigram_count))\n",
    "print(\"Expected Unigrams Count = \", len(unigram_count)   )\n",
    "gram1 = sorted(unigram_prob.items(), key=lambda count: count[1], reverse =True)\n",
    "print(\"Top 10 MLE for unigram\")\n",
    "print (gram1[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training bigram count (seen) = 98513\n",
      "Corpus Training bigram count (distinct) = 43467\n",
      "Expected Training bigram Count (distinct) =  57289761\n",
      "Top 10 MLE for bigram\n",
      "[('<s> start', 0.000182), ('<s> jephro', 0.000182), ('<s> owe', 0.000182), ('<s> visited', 0.000182), ('<s> recently', 0.000182), ('<s> threatens', 0.000182), ('<s> youd', 0.000182), ('<s> evidence', 0.000182), ('<s> vincent', 0.000182), ('<s> coarse', 0.000182)]\n"
     ]
    }
   ],
   "source": [
    "####Bigram tokens\n",
    "\n",
    "biwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-1:\n",
    "        break\n",
    "    biwords.append(item+' '+word_train[index+1])\n",
    "# print(biwords)\n",
    "bigram_count = Counter(biwords)\n",
    "\n",
    "# Bigram Probabilities with and without smoothing\n",
    "bigram_prob = {}\n",
    "for key in bigram_count:\n",
    "    uniword = key.split(' ')\n",
    "#     print(uniword[0])\n",
    "#     print(key)\n",
    "    if (bigram_count[key] == 0):\n",
    "        bigram_prob[key] =0\n",
    "        bigram_prob_smooth[key] = 0\n",
    "    else:\n",
    "        bigram_prob[key] = round( bigram_count.get(key) / float(unigram_count.get(uniword[0])), 6)\n",
    "print(\"Corpus Training bigram count (seen) =\", sum(list(bigram_count.values())))\n",
    "print(\"Corpus Training bigram count (distinct) =\", len(bigram_count))\n",
    "print(\"Expected Training bigram Count (distinct) = \", (len(unigram_count) * len(unigram_count)))  \n",
    "\n",
    "#displaying Probabilities for bigram\n",
    "gram2 = sorted(bigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Top 10 MLE for bigram\")\n",
    "print (gram2[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training trigram count (seen) = 98512\n",
      "Corpus Training trigram count (distinct) = 74686\n",
      "Training Expected trigrams Count (distinct) =  433626201009\n",
      "Least 10 MLE for trigram\n",
      "[('</s> <s> start', 0.000182), ('</s> <s> jephro', 0.000182), ('</s> <s> owe', 0.000182), ('</s> <s> visited', 0.000182), ('</s> <s> recently', 0.000182), ('</s> <s> threatens', 0.000182), ('</s> <s> youd', 0.000182), ('</s> <s> evidence', 0.000182), ('</s> <s> vincent', 0.000182), ('</s> <s> coarse', 0.000182)]\n"
     ]
    }
   ],
   "source": [
    "####Trigram Tokens\n",
    "triwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-2:\n",
    "        break\n",
    "    triwords.append(item+' '+word_train[index+1]+' '+word_train[index+2])\n",
    "trigram_count = Counter(triwords)\n",
    "\n",
    "trigram_prob = {}\n",
    "for key in trigram_count:\n",
    "    biword = key.split(' ')\n",
    "    trigram_prob[key] = round( trigram_count.get(key) / bigram_count.get(biword[0] +' ' + biword[1]), 6)\n",
    "\n",
    "\n",
    "print(\"Corpus Training trigram count (seen) =\", sum(list(trigram_count.values())))\n",
    "print(\"Corpus Training trigram count (distinct) =\", len(trigram_count))\n",
    "print(\"Training Expected trigrams Count (distinct) = \", len(unigram_count) * len(unigram_count) * len(unigram_count)   )\n",
    "\n",
    "gram3 = sorted(trigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Least 10 MLE for trigram\")\n",
    "print (gram3[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training quadrigram count (seen) = 98511\n",
      "Corpus Training quadrigram count (distinct) = 89722\n",
      "Expected quadrigrams Count (distinct) =  3282116715437121\n",
      "Least 10 MLE for quadrigram\n",
      "[('</s> <s> i fully', 0.001247), ('</s> <s> i guessed', 0.001247), ('</s> <s> i warn', 0.001247), ('</s> <s> i might', 0.001247), ('</s> <s> i advertised', 0.001247), ('</s> <s> i seated', 0.001247), ('</s> <s> i assured', 0.001247), ('</s> <s> i wouldnt', 0.001247), ('</s> <s> i yelled', 0.001247), ('</s> <s> i braved', 0.001247)]\n"
     ]
    }
   ],
   "source": [
    "####Quadrigram Tokens\n",
    "\n",
    "quadriwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-3:\n",
    "        break\n",
    "    quadriwords.append(item+' '+word_train[index+1]+' '+word_train[index+2]+' '+word_train[index+3])\n",
    "quadrigram_count = Counter(quadriwords)\n",
    "# print(quadrigram_count)\n",
    "\n",
    "quadrigram_prob = {}\n",
    "for key in quadrigram_count:\n",
    "    triword = key.split(' ')\n",
    "#     print(triword[0:3])\n",
    "#     print(key)\n",
    "    quadrigram_prob[key] = round( quadrigram_count.get(key) / trigram_count.get(triword[0] +' ' + triword[1]+' ' + triword[2]), 6)\n",
    "# print(quadrigram_prob)\n",
    "\n",
    "print(\"Corpus Training quadrigram count (seen) =\", sum(list(quadrigram_count.values())))\n",
    "print(\"Corpus Training quadrigram count (distinct) =\", len(quadrigram_count))\n",
    "print(\"Expected quadrigrams Count (distinct) = \", len(unigram_count) * len(unigram_count) * len(unigram_count)  * len(unigram_count)  )\n",
    "\n",
    "gram4 = sorted(quadrigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Least 10 MLE for quadrigram\")\n",
    "print (gram4[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Training pentigram count (seen) = 98510\n",
      "Corpus Training pentigram count (distinct) = 95769\n",
      "Expected pentigrams Count =  24842341419143568849\n",
      "Least 10 MLE for pentigram\n",
      "[('</s> <s> it is past', 0.007752), ('</s> <s> it is said', 0.007752), ('</s> <s> it is high', 0.007752), ('</s> <s> it is just', 0.007752), ('</s> <s> it is well', 0.007752), ('</s> <s> it is due', 0.007752), ('</s> <s> it is wednesday', 0.007752), ('</s> <s> it is one', 0.007752), ('</s> <s> it is really', 0.007752), ('</s> <s> it is fear', 0.007752)]\n"
     ]
    }
   ],
   "source": [
    "####Pentigram Tokens\n",
    "\n",
    "pentiwords = []\n",
    "for index, item in enumerate(word_train):\n",
    "    if index == len(word_train)-4:\n",
    "        break\n",
    "    pentiwords.append(item+' '+word_train[index+1]+' '+word_train[index+2]+' '+word_train[index+3]+' '+word_train[index+4])\n",
    "pentigram_count = Counter(pentiwords)\n",
    "# print(pentigram_count)\n",
    "\n",
    "pentigram_prob = {}\n",
    "for key in pentigram_count:\n",
    "    quadriword = key.split(' ')\n",
    "#     print(quadriword[0:4])\n",
    "#     print(key)\n",
    "    pentigram_prob[key] = round( pentigram_count.get(key) / quadrigram_count.get(quadriword[0] +' ' + quadriword[1]+' ' + quadriword[2]+' ' + quadriword[3]), 6)\n",
    "# print(pentigram_prob)\n",
    "\n",
    "print(\"Corpus Training pentigram count (seen) =\", sum(list(pentigram_count.values())))\n",
    "print(\"Corpus Training pentigram count (distinct) =\", len(pentigram_count))\n",
    "print(\"Expected pentigrams Count = \", len(unigram_count) * len(unigram_count) * len(unigram_count)  * len(unigram_count) * len(unigram_count)  )\n",
    "\n",
    "gram5 = sorted(pentigram_prob.items(), key=lambda count: count[1], reverse =False)\n",
    "print(\"Least 10 MLE for pentigram\")\n",
    "print (gram5[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Building nested dictionary \n",
    "import random\n",
    "unigram_dictt = {}\n",
    "bigram_dictt = {}\n",
    "trigram_dictt = {}\n",
    "quadrigram_dictt = {}\n",
    "pentigram_dictt = {}\n",
    "def build_dictionary(model):\n",
    "    if model == \"unigram\":\n",
    "#         print(\"Unigram Dictionary\")\n",
    "        for i in range(len(words)): \n",
    "            if not unigram_dictt.get(words[i]): \n",
    "                unigram_dictt[words[i]] = 1 \n",
    "            else: \n",
    "                unigram_dictt[words[i]] += 1 \n",
    "        summ = sum (unigram_dictt.values())\n",
    "\n",
    "        for key in unigram_dictt:\n",
    "            prob =round(unigram_dictt.get(key) / summ,6)\n",
    "            unigram_dictt[key] = prob\n",
    "\n",
    "\n",
    "        gram1_iter= iter(unigram_dictt)\n",
    "\n",
    "        \n",
    "    if model == \"bigram\":\n",
    "#         print(\"bigram dictionary\")\n",
    "        for i in range(len(words) - 1): \n",
    "            if not bigram_dictt.get(words[i]): \n",
    "                bigram_dictt[words[i]] = {} \n",
    "            if not bigram_dictt[words[i]].get(words[i+1]): \n",
    "                bigram_dictt[words[i]][words[i+1]] = 1 \n",
    "            else: \n",
    "                bigram_dictt[words[i]][words[i+1]] += 1 \n",
    "        for outer_key in bigram_dictt:\n",
    "            subdict = dict(bigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                bigram_dictt[outer_key][inner_key] = prob\n",
    "        gram2_iter= iter(bigram_dictt)\n",
    "\n",
    "\n",
    "    elif model == \"trigram\":  \n",
    "#         print(\"trigram ditionary\")\n",
    "        for i in range(len(words) - 2): \n",
    "            if not trigram_dictt.get(words[i] + ' ' + words[i+1]): \n",
    "                trigram_dictt[words[i] + ' ' + words[i+1]] = {} \n",
    "            if not trigram_dictt[words[i] + ' ' + words[i+1]].get(words[i+2]): \n",
    "                trigram_dictt[words[i] + ' ' + words[i+1]][words[i+2]] = 1 \n",
    "            else: \n",
    "                trigram_dictt[words[i] + ' ' + words[i+1]][words[i+2]] += 1 \n",
    "    \n",
    "        for outer_key in trigram_dictt:\n",
    "            subdict = dict(trigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                trigram_dictt[outer_key][inner_key] = prob\n",
    "                \n",
    "    \n",
    "        gram3_iter= iter(trigram_dictt)\n",
    "\n",
    "        \n",
    "    elif model == \"quadrigram\":\n",
    "#         print(\"quadrigram dictionary\")\n",
    "        for i in range(len(words) - 3): \n",
    "            if not quadrigram_dictt.get(words[i] + ' ' + words[i+1] + ' ' + words [i+2]): \n",
    "                quadrigram_dictt[words[i] + ' ' + words[i+1]+ ' ' + words[i+2]] = {} \n",
    "            if not quadrigram_dictt[words[i] + ' ' + words[i+1] +' ' + words[i+2]].get(words[i+3]): \n",
    "                quadrigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]][words[i+3]] = 1 \n",
    "            else: \n",
    "                quadrigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]][words[i+3]] += 1 \n",
    "        for outer_key in quadrigram_dictt:\n",
    "            subdict = dict(quadrigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                quadrigram_dictt[outer_key][inner_key] = prob\n",
    "        gram4_iter= iter(quadrigram_dictt)\n",
    "\n",
    "\n",
    "    elif model == \"pentigram\":\n",
    "#         print(\"pentigram dictionary\")\n",
    "        for i in range(len(words) - 4): \n",
    "            if not pentigram_dictt.get(words[i] + ' ' + words[i+1] + ' ' + words [i+2]+ ' ' + words [i+3]): \n",
    "                pentigram_dictt[words[i] + ' ' + words[i+1]+ ' ' + words[i+2]+ ' ' + words [i+3]] = {} \n",
    "            if not pentigram_dictt[words[i] + ' ' + words[i+1] +' ' + words[i+2]+ ' ' + words [i+3]].get(words[i+4]): \n",
    "                pentigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]+ ' ' + words [i+3]][words[i+4]] = 1 \n",
    "            else: \n",
    "                pentigram_dictt[words[i] + ' ' + words[i+1] + ' ' + words[i+2]+ ' ' + words [i+3]][words[i+4]] += 1 \n",
    "        for outer_key in pentigram_dictt:\n",
    "            subdict = dict(pentigram_dictt[outer_key])\n",
    "            summ = sum (subdict.values())\n",
    "            for inner_key in subdict: \n",
    "                prob =round(subdict.get(inner_key)/ summ,6)\n",
    "                pentigram_dictt[outer_key][inner_key] = prob\n",
    "        gram5_iter= iter(pentigram_dictt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************Generating Random sentences based on unigram ***********************\n",
      "\n",
      "<s> oclock audible donna refers visitors hole rather office veiled settling supposed officials wheeler foreman influence strand natured carved delirium serpent places served escort surly fiery reproach shelf supporting boat</s> \n",
      "\n",
      "<s> valet smiling waiter any) dated perform too union specimen rubber absence peaked heroic generations regretted 4th maintenance waistcoat temper frowning calf look troubled pencil horrid fits conception unmistakable requests</s> \n",
      "\n",
      "<s> conclusion dated originator entered 6d stark madam started balustraded crossed faith edge discretion occupations mostly foretold prosecution txt jump affecting noised motives steep hardy feminine erroneous policeman ostlers petulance</s> \n",
      "\n",
      "<s> silvered activity sovereigns league sun mile pit labyrinth san allusion tied brims deepest thread demeanour peasant constraint 18 arresting cab concentrate friends road addressing seconds parcel renew plumber similar</s> \n",
      "\n",
      "<s> org/fundraising referred tenant unnecessary 19th science about clenched perpetrators shade fatigued attain offer memoir bloodstains shimmering sherry senders ones morris accompanied loafer redistribute ago permitted trifle encourage sovereign referred</s> \n",
      "\n",
      "<s> pale lestrades landlord scar clays servitude allows carrying locket perform apart threatened disconnected copying fathers catastrophe doubtless rueful modern collar replacement chestnut tidy unique readily 60s locality adds transaction</s> \n",
      "\n",
      "<s> veil stable outer pain alteration supposition passionate linked isle fagged eg hellish witted squatted clark majestys snatches tomboy whined peeped outweigh bandages bordered anstruther cluster professionally petersons apparition shadow</s> \n",
      "\n",
      "<s> deserts number thus using drawing gentleman miniature louder ignotum together peterson absurd fabrication topped briskly upper digesting barton averse companions carte map pillows nobleman villainy april ensuring howling insists</s> \n",
      "\n",
      "*********************Generating Random sentences based on bigram ***********************\n",
      "\n",
      "<s> read this web site of colour of foolscap paper and more afraid so expensive a lantern and counties bank she states where more bizarre </s></s> \n",
      "\n",
      "<s> 6d </s></s> \n",
      "\n",
      "<s> certainly speak loudly protesting to form including how dangerous man fierce eddy between puckered lids </s></s> \n",
      "\n",
      "<s> several in france upon bohemian nobleman swung through which did also may assume </s></s> \n",
      "\n",
      "<s> fritz </s></s> \n",
      "\n",
      "<s> lady with horror there been returning home for wear </s></s> \n",
      "\n",
      "<s> yours perhaps mrs hudson has agreed to fetch the intention i attempt might die under these garments thrust them less would you drove on entering her knees </s></s> \n",
      "\n",
      "<s> turn like the colony of flesh coloured tint and typewriting which king to miss your filthy hands my opinion </s></s> \n",
      "\n",
      "*********************Generating Random sentences based on trigram ***********************\n",
      "\n",
      "<s> undoubtedly so  </s> </s> \n",
      "\n",
      "<s> a thousand  wrinkles  burned  yellow  with  the  shutter  half  open  throwing  a  brilliant  beam  of </s> \n",
      "\n",
      "<s> principal of  the  wifes  death  was  little  difficulty  in  the  evenings  transform  myself  into  a </s> \n",
      "\n",
      "<s> principal of  the  back  yard  and  smoked  very  heavily  upon  my  doing  so  were  the </s> \n",
      "\n",
      "<s> black jack  of  ballarat  </s> </s> \n",
      "\n",
      "<s> irenes photograph  </s> </s> \n",
      "\n",
      "<s> really now  </s> </s> \n",
      "\n",
      "<s> professor michael  s  hart  is  the  letter  was  superscribed  to  sherlock  holmes  insight  that  i </s> \n",
      "\n",
      "*********************Generating Random sentences based on quadrigram ***********************\n",
      "\n",
      "<s> for some years  and  an  extra  couple  of  hundred  would  have  been  she  and  that  his </s> \n",
      "\n",
      "<s> last week he  hurled  the  local  blacksmith  over  a  parapet  into  a  stream  and  it  was </s> \n",
      "\n",
      "<s> thank god he  cried  </s> </s> \n",
      "\n",
      "<s> surely your medical  experience  would  tell  you  watson  that  weakness  in  one  limb  is  often  compensated </s> \n",
      "\n",
      "<s> stolen </s></s> \n",
      "\n",
      "<s> both these witnesses  depose  that  mr  mccarthy  was  very  anxious  that  there  should  be  a  bachelor </s> \n",
      "\n",
      "<s> showing that she  had  divined  that  i  had  solved  my  problem  </s> </s> \n",
      "\n",
      "<s> international donations are  gratefully  accepted  but  we  cannot  make  our  way  in  </s> </s> \n",
      "\n",
      "*********************Generating Random sentences based on pentigram ***********************\n",
      "\n",
      "<s> turner had a considerable  household  some  half  dozen  at  the  least  </s> </s> \n",
      "\n",
      "<s> lord robert walsingham de  vere  st  simon  second  son  of  the  duke  of  balmoral  </s> </s> \n",
      "\n",
      "<s> voilà tout </s></s> \n",
      "\n",
      "<s> your husband as far  as  you  could  see  had  his  ordinary  clothes  on  </s> </s> \n",
      "\n",
      "<s> excuse me he said  but  it  is  not  my  custom  to  discuss  my  most  intimate  personal </s> \n",
      "\n",
      "<s> black jack of ballarat  was  the  name  i  went  under  and  our  party  is  still  remembered </s> \n",
      "\n",
      "<s> dr bechers </s></s> \n",
      "\n",
      "<s> will you come with  me  </s> </s> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def Gen_Sentence(model_name):\n",
    "    print(\"*********************Generating Random sentences based on\", model_name, \"***********************\\n\")\n",
    "    if (model_name == \"unigram\"):\n",
    "        for i in range(0,8):\n",
    "            new = \"\"\n",
    "            sen_gen = '<s>'\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = unigram_dictt\n",
    "                if subdict:\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "            \n",
    "    if model_name == \"bigram\":\n",
    "        for i in range(0,8):\n",
    "            prev_word =\"<s>\" \n",
    "            new = \"\"\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = bigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    new= random.choice(list(subdict))\n",
    "                prev_word = new\n",
    "                sen_gen = sen_gen + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "\n",
    "        \n",
    "    if model_name == \"trigram\":\n",
    "         for i in range(0,8):\n",
    "            temp='<s>'\n",
    "            new =  random.choice(list(bigram_dictt.get(temp)))\n",
    "            prev_word = temp + \" \" + new\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = trigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    temp = new\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new + \" \" \n",
    "                prev_word = temp + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "    if model_name == \"quadrigram\":\n",
    "        for i in range(0,8):\n",
    "            temp1='<s>'\n",
    "            temp2 =  random.choice(list(bigram_dictt.get(temp1)))\n",
    "            new =  random.choice(list(trigram_dictt.get(temp1 + \" \" + temp2)))\n",
    "            prev_word = temp1 + \" \" + temp2 + \" \" + new\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = quadrigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    temp1 = temp2\n",
    "                    temp2 = new\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new + \" \" \n",
    "                prev_word = temp1 +  \" \" + temp2 + \" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "    if model_name == \"pentigram\":\n",
    "        for i in range(0,8):\n",
    "            temp1='<s>'\n",
    "            temp2 =  random.choice(list(bigram_dictt.get(temp1)))\n",
    "            temp3 =  random.choice(list(trigram_dictt.get(temp1 + \" \" + temp2)))\n",
    "            new =   random.choice(list(quadrigram_dictt.get(temp1 + \" \" + temp2 + \" \" + temp3)))\n",
    "            prev_word = temp1 + \" \" + temp2 + \" \" +temp3 + \" \"+ new\n",
    "            sen_gen = prev_word\n",
    "            while (new != \"</s>\" and len(sen_gen.split(' ')) < 30):\n",
    "                subdict = pentigram_dictt.get(prev_word)\n",
    "                if subdict:\n",
    "                    temp1 = temp2\n",
    "                    temp2 = temp3\n",
    "                    temp3 = new\n",
    "                    listt = np.random.multinomial(20, list(subdict.values()),1)\n",
    "                    new= random.choice(list(subdict))\n",
    "                sen_gen = sen_gen + \" \" + new + \" \" \n",
    "                prev_word = temp1 +  \" \" + temp2 + \" \" + temp3 +\" \" + new\n",
    "            sen_gen =sen_gen +'</s>'\n",
    "            print (sen_gen, \"\\n\")\n",
    "\n",
    "        \n",
    "model = [ 'unigram', 'bigram', 'trigram', 'quadrigram', 'pentigram']\n",
    "for modd in model:\n",
    "    build_dictionary(modd)\n",
    "    Gen_Sentence (modd)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed value of d for good turing= 0.9\n"
     ]
    }
   ],
   "source": [
    "#Caluclating d values for good turing\n",
    "\n",
    "countOfCounts = {}\n",
    "gd_count= {}\n",
    "def countOfCountsTable():\n",
    "    \n",
    "\n",
    "    count_list =  set(bigram_count.values())\n",
    "    countsOfCounts = {}\n",
    "    for c in count_list :\n",
    "        countOfCounts[c] = 0\n",
    "        for key, keycount in bigram_count.items():\n",
    "            if keycount == c:\n",
    "                countOfCounts[c] += 1\n",
    "    return countOfCounts\n",
    "\n",
    "\n",
    "countOfCounts = countOfCountsTable()\n",
    "N=sum(list(bigram_count.values()))\n",
    "dist = len(bigram_count.values())\n",
    "N_0 = (len(unigram_count) * len(unigram_count)) - dist\n",
    "# print(\"Bigrams seen =\", N)\n",
    "# print(\"distinct Bigrams\", dist)\n",
    "# print(\"Bigrams not seen\", N_0)\n",
    "\n",
    "\n",
    "gd_count [0] = countOfCounts[1] / N\n",
    "countOfCounts[0] =N_0\n",
    "d =0 \n",
    "for i in range(1,10):     #max(countOfCounts)\n",
    "    gd_count[i] = ((i+1) * countOfCounts[i+1]) /countOfCounts [i]\n",
    "    \n",
    "# print(\"Updated count values of bigrams corresponding to each original count is mentioned in key value pair\")\n",
    "\n",
    "for i in range (1,7):\n",
    "    d = d +(i - gd_count[i])\n",
    "#     print(i, gd_count[i])\n",
    "d=  round(d/6, 2)\n",
    "print(\"Observed value of d for good turing=\", d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating  Smooth probabilities Add1 and Good Turing\n",
    "bigram_prob_smooth = {}\n",
    "bigram_count_smooth = {}\n",
    "bigram_prob_gd = {}\n",
    "bigram_count_gd = {}\n",
    "\n",
    "\n",
    "for key in bigram_count:\n",
    "    uniword = key.split(' ')\n",
    "#     print(uniword[0])\n",
    "#     print(key)\n",
    "        \n",
    "        ######Calculating Add 1 Smoothed count and probability#############\n",
    "        \n",
    "    smooth = (bigram_count.get(key) + 1) / (unigram_count.get(uniword[0]) + (len(unigram_count)))   \n",
    "    #Adding one to each word and dividing by vocaulary size for updating the count\n",
    "    bigram_prob_smooth[key] = round (smooth, 6)     #Updated probaility\n",
    "    bigram_count_smooth[key] = bigram_prob_smooth[key] * unigram_count[uniword[0]]    #Updated Add 1 smooth count\n",
    "    ######Calculating Good Turing Smoothed count and probability#############\n",
    "        \n",
    "    bigram_count_gd[key] = bigram_count[key] - d    #Using observed d value for calculating updated gd count\n",
    "        \n",
    "    bigram_prob_gd[key] = ( bigram_count_gd[key] / unigram_count[uniword[0]])   #Calulating probability with updated mle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sentence from thetest dataset = <s> you have called me names enough said he i will not stand it any longer </s>\n",
      "Probability with unigram, = (Unsmoothed) 4.78815597392e-45\n",
      "Probability with bigram, = (Unsmoothed) 2.41264062984e-17\n",
      "Probability with trigram, = (Unsmoothed) 0.00049785744825\n",
      "Probability with quadrigram, = (Unsmoothed) 1.0\n",
      "Probability with pentigram, = (Unsmoothed) 1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculating Probability of a given sentence with some specific model\n",
    "import math as calc\n",
    "\n",
    "def probability(sentence, model_name):\n",
    "    P= 0\n",
    "    sent_words = sentence.lower().split(' ')\n",
    "    if model_name == 'unigram':\n",
    "      \n",
    "        for item in sent_words:\n",
    "            if item in unigram_prob:\n",
    "                P = P + calc.log(unigram_prob[item]) \n",
    "        return P\n",
    "    \n",
    "    elif model_name == 'bigram':\n",
    "        sent_biword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-1:\n",
    "                break\n",
    "            sent_biword.append(item+' '+sent_words[index+1])\n",
    "        for item in sent_biword:\n",
    "            if item in bigram_prob:\n",
    "                P = P +calc.log(bigram_prob[item])\n",
    "        return P\n",
    "    \n",
    "    elif model_name == 'add1':\n",
    "        sent_biword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-1:\n",
    "                break\n",
    "            sent_biword.append(item+' '+sent_words[index+1])\n",
    "        for item in sent_biword:\n",
    "            if item in bigram_prob_smooth:\n",
    "                P = P +calc.log(bigram_prob_smooth[item])\n",
    "        return P\n",
    "    elif model_name == 'gd':\n",
    "        sent_biword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-1:\n",
    "                break\n",
    "            sent_biword.append(item+' '+sent_words[index+1])\n",
    "        for item in sent_biword:\n",
    "            if item in bigram_prob_gd:\n",
    "#                 print(item, bigram_prob[item])\n",
    "                P = P +calc.log(bigram_prob_gd[item])\n",
    "        return P\n",
    "    elif model_name == 'trigram':\n",
    "        sent_triword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-2:\n",
    "                break\n",
    "            sent_triword.append(item+' '+sent_words[index+1]+' '+sent_words[index+2])\n",
    "        for item in sent_triword:\n",
    "            if item in trigram_prob:\n",
    "                P = P + calc.log(trigram_prob[item])\n",
    "        return P\n",
    "    elif model_name == 'quadrigram':\n",
    "        sent_quadriword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-3:\n",
    "                break\n",
    "            sent_quadriword.append(item+' '+sent_words[index+1]+' '+sent_words[index+2]+' '+sent_words[index+3])\n",
    "        for item in sent_quadriword:\n",
    "            if item in quadrigram_prob:\n",
    "                P = P + calc.log(quadrigram_prob[item])\n",
    "        return P\n",
    "    elif model_name == 'pentigram':\n",
    "        sent_pentiword = []\n",
    "        for index, item in enumerate(sent_words):\n",
    "            if index == len(sent_words)-4:\n",
    "                break\n",
    "            sent_pentiword.append(item+' '+sent_words[index+1]+' '+sent_words[index+2]+' '+sent_words[index+3]+' '+sent_words[index+4])\n",
    "        for item in sent_pentiword:\n",
    "            if item in pentigram_prob:\n",
    "                P = P + calc.log(pentigram_prob[item])\n",
    "        return P\n",
    "    \n",
    "    \n",
    "from random import randint\n",
    "sent = test[randint(0, len(test)-1)]    # Randomly picking the sentence from test data set\n",
    "print (\"Random sentence from thetest dataset =\", sent)\n",
    "P  = probability(sent, \"unigram\")\n",
    "print(\"Probability with unigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "P = probability(sent, \"bigram\")\n",
    "print(\"Probability with bigram, = (Unsmoothed)\"  ,np.exp(P))\n",
    "P  = probability(sent, \"trigram\")\n",
    "print(\"Probability with trigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "P  =probability(sent, \"quadrigram\")\n",
    "print(\"Probability with quadrigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "P  =probability(sent, \"pentigram\")\n",
    "print(\"Probability with pentigram, = (Unsmoothed)\"  , np.exp(P))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsmoothed Count ' say is ' =  1\n",
      "Smoothed Count ' say is '= 0.021141\n",
      "Unsmoothed Count ' snuff then ' =  1\n",
      "Smoothed Count ' snuff then '= 0.001056\n",
      "Unsmoothed Count ' the creases ' =  1\n",
      "Smoothed Count ' the creases '= 0.7661\n",
      "Unsmoothed Count ' winchester to ' =  1\n",
      "Smoothed Count ' winchester to '= 0.002112\n",
      "Unsmoothed Count ' lee a ' =  1\n",
      "Smoothed Count ' lee a '= 0.0015840000000000001\n",
      "Unsmoothed Count ' now made ' =  1\n",
      "Smoothed Count ' now made '= 0.046439999999999995\n",
      "Unsmoothed Count ' away </s> ' =  6\n",
      "Smoothed Count ' away </s> '= 0.07686\n",
      "Unsmoothed Count ' even gaunter ' =  1\n",
      "Smoothed Count ' even gaunter '= 0.01572\n",
      "Unsmoothed Count ' more precious ' =  1\n",
      "Smoothed Count ' more precious '= 0.036778\n",
      "Unsmoothed Count ' his motives ' =  1\n",
      "Smoothed Count ' his motives '= 0.220195\n",
      "As we can see, there is huge reduction in the number of counts of particular bigrams, When we do Add-one Smoothing.This happens because we have distributed the probability mass of existing bigrams to the bigrams which do not exist in thecorpus. So we have to reduce the probability of already existing bigrams and hence the their count gets decreased, but, so huge reduction of count is not desirable. Therefore Add 1 smoothing is not a good solution for language modelling. \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for i in range (0, 10):\n",
    "    key =random.choice(list(bigram_count.keys()))\n",
    "    print(\"Unsmoothed Count '\", key, \"' = \", bigram_count[key])\n",
    "    print (\"Smoothed Count '\", key, \"'=\",  bigram_count_smooth[key])\n",
    "print(\"As we can see, there is huge reduction in the number of counts of particular bigrams, When we do Add-one Smoothing.\\\n",
    "This happens because we have distributed the probability mass of existing bigrams to the bigrams which do not exist in the\\\n",
    "corpus. So we have to reduce the probability of already existing bigrams and hence the their count gets decreased, but, so \\\n",
    "huge reduction of count is not desirable. Therefore Add 1 smoothing is not a good solution for language modelling. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sentence from the test = <s> i had almost overcome my pride so far as to go back to the agency and inquire whether the place was still open when i received this letter from the gentleman himself </s>\n",
      "inside add1\n",
      "Perplexity ,add1 = 76.9025407596\n",
      "Perplexity ,Good Turing = 105.484384118\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "sent = test[randint(0, len(test)-1)]    # Randomly picking the sentence from test data set\n",
    "print (\"Random sentence from the test =\", sent)\n",
    "\n",
    "prob = probability(sent, \"add1\")\n",
    "prob =np.exp(prob)\n",
    "# print(\"Probability \", prob)\n",
    "perp = pow(prob, 1/float(len(sent))) * len(sent)\n",
    "print(\"Perplexity ,add1 =\",  perp )\n",
    "\n",
    "\n",
    "prob = probability(sent, \"gd\")\n",
    "prob =np.exp(prob)\n",
    "perp = pow(prob, 1/float(len(sent))) * len(sent) \n",
    "print(\"Perplexity ,Good Turing =\",  perp) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
